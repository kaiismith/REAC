{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>329.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.589666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.492644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Label\n",
       "count  329.000000\n",
       "mean     0.589666\n",
       "std      0.492644\n",
       "min      0.000000\n",
       "25%      0.000000\n",
       "50%      1.000000\n",
       "75%      1.000000\n",
       "max      1.000000"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data_new.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-cheat:  135\n",
      "Cheat:  194\n",
      "(222, 48)\n"
     ]
    }
   ],
   "source": [
    "print(\"Non-cheat: \", len(df[df['Label']==0]))\n",
    "print(\"Cheat: \", len(df[df['Label']==1]))\n",
    "\n",
    "# diff = abs(len(df[df['Label']==0]) - len(df[df['Label']==1]))\n",
    "\n",
    "grouped = df.groupby(df.Label)\n",
    "df1 = grouped.get_group(1)\n",
    "df2 = grouped.get_group(0)\n",
    "\n",
    "df2_1 = df2.iloc[:135,:]\n",
    "df2_2 = df2.iloc[135:194,:]\n",
    "\n",
    "df1_train = df1.iloc[:111,:]\n",
    "df2_train = df2_1.iloc[:111,:]\n",
    "\n",
    "df1_test = df1.iloc[111:135,:]\n",
    "df2_test = df2_1.iloc[111:135,:]\n",
    "\n",
    "train = pd.concat([df1_train, df2_train])\n",
    "test  = pd.concat([df1_test, df2_test, df2_2])\n",
    "\n",
    "# shuffle data\n",
    "train = train.sample(frac=1)\n",
    "test  = test.sample(frac=1)\n",
    "\n",
    "print((len(train), len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-cheat in trainsets:  111\n",
      "Cheat in trainsets:  111\n"
     ]
    }
   ],
   "source": [
    "print(\"Non-cheat in trainsets: \", len(train[train['Label']==0]))\n",
    "print(\"Cheat in trainsets: \", len(train[train['Label']==1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parse data from string to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(series):\n",
    "    final_series = []\n",
    "    for ser in series:\n",
    "        temp = []\n",
    "        for x in \"[],\":\n",
    "            ser = ser.replace(x, \"\")\n",
    "        new_ser  = np.fromstring(ser, dtype=float, sep=\" \")\n",
    "        for i in range(0, len(new_ser), 3):\n",
    "            chunk = [new_ser[i], new_ser[i + 1], new_ser[i + 2]]\n",
    "            temp.append(chunk)\n",
    "        final_series.append(temp)\n",
    "    return np.array(final_series, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the longest sequence of vector in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1294"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = 0\n",
    "for lgaze in parseData(df['Left Gaze']):\n",
    "    if len(lgaze) > max_length:\n",
    "        max_length = len(lgaze)\n",
    "        \n",
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pad the dataset to the longest sequence size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def padData(series, length):\n",
    "    for idx, ser in enumerate(series):\n",
    "        times = math.floor(length / len(ser))\n",
    "        add = length % len(ser)\n",
    "        \n",
    "        temp = ser[::-1]\n",
    "        for _ in range(1, times):\n",
    "            series[idx] = np.append(series[idx], temp, axis=0)\n",
    "            temp = temp[::-1]\n",
    "        if add != 0:\n",
    "            series[idx] = np.append(series[idx], temp[0:add], axis=0)\n",
    "    return series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conv1D -> AveragePooling1D -> Conv1D -> AveragePooling1D -> LSTM -> Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense, AveragePooling1D, LSTM, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, History\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def init_model_38():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, padding=\"same\", activation='relu', input_shape=(max_length, 12)))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, padding=\"same\", activation='relu', input_shape=(max_length, 12)))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(LSTM(12))\n",
    "    \n",
    "    adam = optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2, activation = 'softmax')) # We have only 2 classes: Non-cheat & Cheat\n",
    "    \n",
    "    model.compile(optimizer=adam,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_33():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, padding=\"same\", activation='relu', input_shape=(max_length, 12)))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(LSTM(12))\n",
    "    \n",
    "    adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2, activation = 'softmax')) # We have only 2 classes: Non-cheat & Cheat\n",
    "    \n",
    "    model.compile(optimizer=adam,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_35():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, padding=\"same\", activation='relu', input_shape=(max_length, 12)))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, padding=\"same\", activation='relu', input_shape=(max_length, 12)))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, padding=\"same\", activation='relu', input_shape=(max_length, 12)))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(LSTM(12))\n",
    "    \n",
    "    adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2, activation = 'softmax')) # We have only 2 classes: Non-cheat & Cheat\n",
    "    \n",
    "    model.compile(optimizer=adam,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_36():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, padding=\"same\", activation='relu', input_shape=(max_length, 12)))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, padding=\"same\", activation='relu', input_shape=(max_length, 12)))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, padding=\"same\", activation='relu', input_shape=(max_length, 12)))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, padding=\"same\", activation='relu', input_shape=(max_length, 12)))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(LSTM(12))\n",
    "    \n",
    "    adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2, activation = 'softmax')) # We have only 2 classes: Non-cheat & Cheat\n",
    "    \n",
    "    model.compile(optimizer=adam,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_37():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, padding=\"same\", activation='relu', input_shape=(max_length, 12)))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, padding=\"same\", activation='relu', input_shape=(max_length, 12)))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, padding=\"same\", activation='relu', input_shape=(max_length, 12)))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, padding=\"same\", activation='relu', input_shape=(max_length, 12)))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, padding=\"same\", activation='relu', input_shape=(max_length, 12)))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(LSTM(12))\n",
    "    \n",
    "    adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2, activation = 'softmax')) # We have only 2 classes: Non-cheat & Cheat\n",
    "    \n",
    "    model.compile(optimizer=adam,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_45():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, padding=\"same\", activation='relu', input_shape=(max_length, 12)))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, padding=\"same\", activation='relu', input_shape=(max_length, 12)))\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, padding=\"same\", activation='relu', input_shape=(max_length, 12)))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(LSTM(12))\n",
    "    \n",
    "    adam = tf.keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2, activation = 'softmax')) # We have only 2 classes: Non-cheat & Cheat\n",
    "    \n",
    "    model.compile(optimizer=adam,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_gaze_train = train[\"Right Gaze\"]\n",
    "left_gaze_train  = train[\"Left Gaze\"]\n",
    "right_head_train = train[\"Right HeadPose\"]\n",
    "left_head_train  = train[\"Left HeadPose\"]\n",
    "\n",
    "label_train = train['Label']\n",
    "\n",
    "right_gaze_train, left_gaze_train, right_head_train, left_head_train = parseData(right_gaze_train), parseData(left_gaze_train), parseData(right_head_train), parseData(left_head_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize new data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_head_train  = padData(left_head_train,  max_length)\n",
    "right_head_train = padData(right_head_train, max_length)\n",
    "left_gaze_train  = padData(left_gaze_train,  max_length)\n",
    "right_gaze_train = padData(right_gaze_train, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.array(label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "for i in range(len(label_train)):\n",
    "    y_train.append(\n",
    "        tf.convert_to_tensor(\n",
    "            np.reshape(tf.keras.utils.to_categorical(label_train[i], num_classes=2), (1, 2))                 \n",
    "                            )\n",
    "             )\n",
    "    \n",
    "y_train = tf.convert_to_tensor(np.vstack(y_train), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ -1.382  28.187 -28.221 ...   6.707   2.788   7.264]\n",
      "  [  5.656  31.011  31.523 ...  10.207   3.289  10.724]\n",
      "  [  9.22   30.034  31.417 ...   7.057  -5.121   8.719]\n",
      "  ...\n",
      "  [  2.36    9.203   9.501 ...   5.435 -11.421  12.648]\n",
      "  [  9.318  14.225  17.005 ...   4.445 -11.692  12.509]\n",
      "  [ 11.962  10.637  16.008 ...   6.884 -11.436  13.348]]\n",
      "\n",
      " [[ 28.678  21.249  35.693 ...  22.896  14.792  27.259]\n",
      "  [ 23.722  25.904  35.124 ...  13.787  21.24   25.322]\n",
      "  [ 21.455  33.225  39.551 ...   5.358  29.887  30.363]\n",
      "  ...\n",
      "  [ 13.977  73.342  74.662 ... -21.408  80.903 -83.687]\n",
      "  [ 10.534  76.314  77.038 ... -22.389  78.459 -81.592]\n",
      "  [ 11.495  74.187  75.073 ... -24.004  77.375 -81.013]]\n",
      "\n",
      " [[ -6.244  33.211 -33.793 ...   8.802  16.126  18.372]\n",
      "  [ -1.074  30.908 -30.926 ...   9.715  11.446  15.013]\n",
      "  [ 11.383  23.78   26.364 ...  27.407   4.25   27.735]\n",
      "  ...\n",
      "  [-20.486  14.628 -25.172 ...  -4.297   0.989  -4.409]\n",
      "  [ -9.598  13.735 -16.756 ...   7.151   3.127   7.805]\n",
      "  [-11.377   9.602 -14.887 ...   5.488  -2.497   6.03 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-29.176  21.24  -36.089 ... -41.562  32.045 -52.481]\n",
      "  [-61.462  36.411 -71.438 ... -53.186  25.892 -59.153]\n",
      "  [-73.071  27.315 -78.01  ... -69.714  17.9   -71.976]\n",
      "  ...\n",
      "  [ 21.168  36.446  42.147 ...   7.818  35.323  36.177]\n",
      "  [ 22.003  40.218  45.843 ...   9.073  35.341  36.487]\n",
      "  [ 21.466  41.172  46.432 ...   8.243  35.73   36.668]]\n",
      "\n",
      " [[ 44.482   4.375  44.696 ...  36.629  -5.647  37.062]\n",
      "  [ 32.01    5.094  32.413 ...  31.281  -7.796  32.237]\n",
      "  [ 34.861  13.067  37.229 ...  32.594  -0.883  32.606]\n",
      "  ...\n",
      "  [ 27.681  27.075  38.721 ...  31.683  15.641  35.334]\n",
      "  [ 23.26   24.57   33.834 ...  31.326  13.684  34.184]\n",
      "  [ 21.485  25.976  33.71  ...  30.521  14.24   33.68 ]]\n",
      "\n",
      " [[ -3.219  37.824 -37.961 ...   4.009  22.778  23.128]\n",
      "  [  2.784  26.225  26.373 ...  -6.594  22.666 -23.606]\n",
      "  [  5.955  23.608  24.347 ...  -3.083  20.516 -20.746]\n",
      "  ...\n",
      "  [ -1.243  37.426 -37.447 ...   7.02   23.029  24.075]\n",
      "  [  1.828  39.13   39.173 ...  10.653  20.917  23.473]\n",
      "  [ 18.547  18.097  25.913 ...  12.408  18.744  22.478]]], shape=(222, 1294, 12), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]], shape=(222, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "\n",
    "for i in range(len(left_gaze_train)):\n",
    "    x_train.append(tf.convert_to_tensor([\n",
    "                                            np.hstack(\n",
    "                                                        (left_gaze_train[i], right_gaze_train[i], left_head_train[i], right_head_train[i])\n",
    "                                                     )\n",
    "                                            ], dtype=tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "x_train = tf.convert_to_tensor(np.vstack(x_train), dtype=tf.float32)\n",
    "\n",
    "print(x_train)\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model_46():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, padding=\"same\", activation='relu', input_shape=(max_length, 12)))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=12, kernel_size=3, padding=\"same\", activation='relu', input_shape=(max_length, 12)))\n",
    "    \n",
    "    model.add(LSTM(12))\n",
    "    \n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(2, activation = 'softmax')) # We have only 2 classes: Non-cheat & Cheat\n",
    "    \n",
    "    adam = optimizers.Adam(learning_rate=0.005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "    \n",
    "    model.compile(optimizer=adam,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\conda\\envs\\Tensorflow_RTX_Ampere\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 2s 561ms/step - loss: 0.6968 - accuracy: 0.5327 - val_loss: 0.6838 - val_accuracy: 0.4348\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6807 - accuracy: 0.5729 - val_loss: 0.6834 - val_accuracy: 0.5652\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6696 - accuracy: 0.6030 - val_loss: 0.6851 - val_accuracy: 0.5217\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6601 - accuracy: 0.6080 - val_loss: 0.6884 - val_accuracy: 0.4348\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6526 - accuracy: 0.6281 - val_loss: 0.6900 - val_accuracy: 0.3913\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.6479 - accuracy: 0.6281 - val_loss: 0.6906 - val_accuracy: 0.3913\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.6449 - accuracy: 0.6281 - val_loss: 0.6900 - val_accuracy: 0.3913\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6408 - accuracy: 0.6482 - val_loss: 0.6879 - val_accuracy: 0.3913\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6373 - accuracy: 0.6482 - val_loss: 0.6850 - val_accuracy: 0.4348\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6331 - accuracy: 0.6633 - val_loss: 0.6829 - val_accuracy: 0.4348\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6284 - accuracy: 0.6633 - val_loss: 0.6810 - val_accuracy: 0.5217\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.6248 - accuracy: 0.6583 - val_loss: 0.6794 - val_accuracy: 0.5217\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6208 - accuracy: 0.6683 - val_loss: 0.6781 - val_accuracy: 0.5217\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6175 - accuracy: 0.6734 - val_loss: 0.6776 - val_accuracy: 0.5217\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6152 - accuracy: 0.6784 - val_loss: 0.6776 - val_accuracy: 0.5217\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.6125 - accuracy: 0.6784 - val_loss: 0.6771 - val_accuracy: 0.5217\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6093 - accuracy: 0.6834 - val_loss: 0.6763 - val_accuracy: 0.5217\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.6053 - accuracy: 0.6935 - val_loss: 0.6753 - val_accuracy: 0.5217\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6023 - accuracy: 0.6834 - val_loss: 0.6743 - val_accuracy: 0.5217\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.5992 - accuracy: 0.6884 - val_loss: 0.6734 - val_accuracy: 0.5217\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5954 - accuracy: 0.6985 - val_loss: 0.6711 - val_accuracy: 0.5652\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5907 - accuracy: 0.7035 - val_loss: 0.6679 - val_accuracy: 0.5652\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5875 - accuracy: 0.7136 - val_loss: 0.6634 - val_accuracy: 0.6087\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5834 - accuracy: 0.7085 - val_loss: 0.6630 - val_accuracy: 0.6087\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5794 - accuracy: 0.7035 - val_loss: 0.6652 - val_accuracy: 0.6087\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5764 - accuracy: 0.7035 - val_loss: 0.6711 - val_accuracy: 0.5652\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5706 - accuracy: 0.7035 - val_loss: 0.6994 - val_accuracy: 0.5217\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.5625 - accuracy: 0.7186 - val_loss: 0.7270 - val_accuracy: 0.5652\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5517 - accuracy: 0.7186 - val_loss: 0.7497 - val_accuracy: 0.5652\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5498 - accuracy: 0.7186 - val_loss: 0.7401 - val_accuracy: 0.6087\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.5419 - accuracy: 0.7236 - val_loss: 0.7172 - val_accuracy: 0.6087\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.5382 - accuracy: 0.7337 - val_loss: 0.7069 - val_accuracy: 0.6522\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5339 - accuracy: 0.7337 - val_loss: 0.7114 - val_accuracy: 0.6522\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5292 - accuracy: 0.7437 - val_loss: 0.7244 - val_accuracy: 0.6522\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5265 - accuracy: 0.7437 - val_loss: 0.7314 - val_accuracy: 0.6522\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 77ms/step - loss: 0.5225 - accuracy: 0.7437 - val_loss: 0.7275 - val_accuracy: 0.6522\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.5181 - accuracy: 0.7387 - val_loss: 0.7057 - val_accuracy: 0.6522\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5163 - accuracy: 0.7337 - val_loss: 0.7048 - val_accuracy: 0.6522\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.5095 - accuracy: 0.7387 - val_loss: 0.7173 - val_accuracy: 0.6522\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5057 - accuracy: 0.7387 - val_loss: 0.7222 - val_accuracy: 0.6522\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 74ms/step - loss: 0.5009 - accuracy: 0.7387 - val_loss: 0.7177 - val_accuracy: 0.6087\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4965 - accuracy: 0.7387 - val_loss: 0.7037 - val_accuracy: 0.6087\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4923 - accuracy: 0.7487 - val_loss: 0.6983 - val_accuracy: 0.6087\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.4886 - accuracy: 0.7487 - val_loss: 0.6984 - val_accuracy: 0.6087\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4841 - accuracy: 0.7588 - val_loss: 0.6990 - val_accuracy: 0.6087\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.4800 - accuracy: 0.7688 - val_loss: 0.6993 - val_accuracy: 0.6087\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.4769 - accuracy: 0.7688 - val_loss: 0.6955 - val_accuracy: 0.6087\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4743 - accuracy: 0.7688 - val_loss: 0.6859 - val_accuracy: 0.6087\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.4729 - accuracy: 0.7538 - val_loss: 0.6732 - val_accuracy: 0.6087\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4769 - accuracy: 0.7538 - val_loss: 0.6722 - val_accuracy: 0.6087\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.4731 - accuracy: 0.7538 - val_loss: 0.6772 - val_accuracy: 0.6087\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 89ms/step - loss: 0.4722 - accuracy: 0.7588 - val_loss: 0.6798 - val_accuracy: 0.6087\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.4687 - accuracy: 0.7688 - val_loss: 0.6835 - val_accuracy: 0.6087\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4648 - accuracy: 0.7739 - val_loss: 0.6780 - val_accuracy: 0.6087\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.4612 - accuracy: 0.7940 - val_loss: 0.6720 - val_accuracy: 0.6522\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 70ms/step - loss: 0.4615 - accuracy: 0.7889 - val_loss: 0.6668 - val_accuracy: 0.6522\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4572 - accuracy: 0.8040 - val_loss: 0.6649 - val_accuracy: 0.6522\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.4521 - accuracy: 0.8090 - val_loss: 0.6772 - val_accuracy: 0.6522\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4492 - accuracy: 0.8141 - val_loss: 0.6868 - val_accuracy: 0.6087\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4472 - accuracy: 0.7990 - val_loss: 0.6811 - val_accuracy: 0.5652\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.4440 - accuracy: 0.8040 - val_loss: 0.6700 - val_accuracy: 0.6087\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 81ms/step - loss: 0.4410 - accuracy: 0.7990 - val_loss: 0.6665 - val_accuracy: 0.6087\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.4387 - accuracy: 0.7990 - val_loss: 0.6723 - val_accuracy: 0.6087\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4357 - accuracy: 0.8090 - val_loss: 0.6796 - val_accuracy: 0.6087\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4319 - accuracy: 0.8090 - val_loss: 0.6759 - val_accuracy: 0.6087\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4314 - accuracy: 0.8141 - val_loss: 0.6675 - val_accuracy: 0.6087\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 80ms/step - loss: 0.4278 - accuracy: 0.8191 - val_loss: 0.6651 - val_accuracy: 0.6087\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.4258 - accuracy: 0.8241 - val_loss: 0.6681 - val_accuracy: 0.6087\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 82ms/step - loss: 0.4229 - accuracy: 0.8241 - val_loss: 0.6747 - val_accuracy: 0.6087\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4188 - accuracy: 0.8241 - val_loss: 0.6738 - val_accuracy: 0.6087\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4154 - accuracy: 0.8291 - val_loss: 0.6667 - val_accuracy: 0.6087\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.4130 - accuracy: 0.8342 - val_loss: 0.6605 - val_accuracy: 0.6087\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 72ms/step - loss: 0.4108 - accuracy: 0.8342 - val_loss: 0.6609 - val_accuracy: 0.6087\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4071 - accuracy: 0.8392 - val_loss: 0.6675 - val_accuracy: 0.6087\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.4040 - accuracy: 0.8392 - val_loss: 0.6675 - val_accuracy: 0.6087\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.4020 - accuracy: 0.8392 - val_loss: 0.6622 - val_accuracy: 0.6087\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 90ms/step - loss: 0.3995 - accuracy: 0.8342 - val_loss: 0.6382 - val_accuracy: 0.6957\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3973 - accuracy: 0.8342 - val_loss: 0.6302 - val_accuracy: 0.6957\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3944 - accuracy: 0.8392 - val_loss: 0.6306 - val_accuracy: 0.6957\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3921 - accuracy: 0.8392 - val_loss: 0.6334 - val_accuracy: 0.6957\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3893 - accuracy: 0.8442 - val_loss: 0.6325 - val_accuracy: 0.6957\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3859 - accuracy: 0.8492 - val_loss: 0.6345 - val_accuracy: 0.6957\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.3833 - accuracy: 0.8543 - val_loss: 0.6325 - val_accuracy: 0.6957\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 75ms/step - loss: 0.3796 - accuracy: 0.8543 - val_loss: 0.6313 - val_accuracy: 0.6957\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 88ms/step - loss: 0.3765 - accuracy: 0.8543 - val_loss: 0.6296 - val_accuracy: 0.6957\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3733 - accuracy: 0.8543 - val_loss: 0.6300 - val_accuracy: 0.6957\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.3702 - accuracy: 0.8543 - val_loss: 0.6311 - val_accuracy: 0.6957\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3668 - accuracy: 0.8643 - val_loss: 0.6298 - val_accuracy: 0.7391\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3639 - accuracy: 0.8643 - val_loss: 0.6279 - val_accuracy: 0.7391\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3611 - accuracy: 0.8593 - val_loss: 0.6254 - val_accuracy: 0.7391\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 69ms/step - loss: 0.3582 - accuracy: 0.8693 - val_loss: 0.6246 - val_accuracy: 0.7391\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.3551 - accuracy: 0.8643 - val_loss: 0.6254 - val_accuracy: 0.7391\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.3521 - accuracy: 0.8693 - val_loss: 0.6236 - val_accuracy: 0.7391\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.3497 - accuracy: 0.8693 - val_loss: 0.6225 - val_accuracy: 0.7391\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.3470 - accuracy: 0.8744 - val_loss: 0.6227 - val_accuracy: 0.7391\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.3440 - accuracy: 0.8794 - val_loss: 0.6245 - val_accuracy: 0.7391\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.3411 - accuracy: 0.8794 - val_loss: 0.6264 - val_accuracy: 0.7391\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.3382 - accuracy: 0.8794 - val_loss: 0.6260 - val_accuracy: 0.7391\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 78ms/step - loss: 0.3343 - accuracy: 0.8794 - val_loss: 0.6251 - val_accuracy: 0.7391\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.3311 - accuracy: 0.8744 - val_loss: 0.6190 - val_accuracy: 0.7391\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 3s 524ms/step - loss: 0.7997 - accuracy: 0.4824 - val_loss: 0.7715 - val_accuracy: 0.4783\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.7610 - accuracy: 0.4874 - val_loss: 0.7331 - val_accuracy: 0.5217\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.7299 - accuracy: 0.4925 - val_loss: 0.7183 - val_accuracy: 0.5217\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.7031 - accuracy: 0.5327 - val_loss: 0.7076 - val_accuracy: 0.5217\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6902 - accuracy: 0.5377 - val_loss: 0.7027 - val_accuracy: 0.5217\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6835 - accuracy: 0.5427 - val_loss: 0.6962 - val_accuracy: 0.5652\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6709 - accuracy: 0.5779 - val_loss: 0.6905 - val_accuracy: 0.5652\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6604 - accuracy: 0.5829 - val_loss: 0.6855 - val_accuracy: 0.6087\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6528 - accuracy: 0.5879 - val_loss: 0.6920 - val_accuracy: 0.5217\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6457 - accuracy: 0.6131 - val_loss: 0.6843 - val_accuracy: 0.4783\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6416 - accuracy: 0.6181 - val_loss: 0.6809 - val_accuracy: 0.4348\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6316 - accuracy: 0.6332 - val_loss: 0.6842 - val_accuracy: 0.5217\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6269 - accuracy: 0.6583 - val_loss: 0.6815 - val_accuracy: 0.4783\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6231 - accuracy: 0.6784 - val_loss: 0.6871 - val_accuracy: 0.4783\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6195 - accuracy: 0.6734 - val_loss: 0.6908 - val_accuracy: 0.5217\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6149 - accuracy: 0.6884 - val_loss: 0.6933 - val_accuracy: 0.5652\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6095 - accuracy: 0.7085 - val_loss: 0.6938 - val_accuracy: 0.6087\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6035 - accuracy: 0.7286 - val_loss: 0.6932 - val_accuracy: 0.5652\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5980 - accuracy: 0.7337 - val_loss: 0.6927 - val_accuracy: 0.5652\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5924 - accuracy: 0.7286 - val_loss: 0.7007 - val_accuracy: 0.5217\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5863 - accuracy: 0.7236 - val_loss: 0.7152 - val_accuracy: 0.5217\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5793 - accuracy: 0.7337 - val_loss: 0.7176 - val_accuracy: 0.5217\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5726 - accuracy: 0.7588 - val_loss: 0.7168 - val_accuracy: 0.5217\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5627 - accuracy: 0.7688 - val_loss: 0.7078 - val_accuracy: 0.6087\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5565 - accuracy: 0.7688 - val_loss: 0.7003 - val_accuracy: 0.6087\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5493 - accuracy: 0.7839 - val_loss: 0.6943 - val_accuracy: 0.6087\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5391 - accuracy: 0.7940 - val_loss: 0.6875 - val_accuracy: 0.5652\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5339 - accuracy: 0.7940 - val_loss: 0.6810 - val_accuracy: 0.5652\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5272 - accuracy: 0.8040 - val_loss: 0.6923 - val_accuracy: 0.6087\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5258 - accuracy: 0.8090 - val_loss: 0.7086 - val_accuracy: 0.5652\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5264 - accuracy: 0.8090 - val_loss: 0.7077 - val_accuracy: 0.6087\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5230 - accuracy: 0.8040 - val_loss: 0.7013 - val_accuracy: 0.6087\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5187 - accuracy: 0.8040 - val_loss: 0.6950 - val_accuracy: 0.6087\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5128 - accuracy: 0.8040 - val_loss: 0.6927 - val_accuracy: 0.6087\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.5066 - accuracy: 0.8241 - val_loss: 0.6956 - val_accuracy: 0.5652\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5004 - accuracy: 0.8141 - val_loss: 0.7007 - val_accuracy: 0.5652\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4936 - accuracy: 0.8191 - val_loss: 0.7028 - val_accuracy: 0.5217\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4892 - accuracy: 0.8241 - val_loss: 0.7016 - val_accuracy: 0.5217\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4840 - accuracy: 0.8342 - val_loss: 0.6935 - val_accuracy: 0.4783\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4789 - accuracy: 0.8543 - val_loss: 0.6851 - val_accuracy: 0.4783\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4691 - accuracy: 0.8392 - val_loss: 0.6851 - val_accuracy: 0.5217\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4618 - accuracy: 0.8442 - val_loss: 0.6878 - val_accuracy: 0.5217\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4564 - accuracy: 0.8543 - val_loss: 0.6969 - val_accuracy: 0.5217\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4510 - accuracy: 0.8492 - val_loss: 0.6884 - val_accuracy: 0.5652\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4436 - accuracy: 0.8693 - val_loss: 0.6757 - val_accuracy: 0.5652\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4406 - accuracy: 0.8543 - val_loss: 0.6897 - val_accuracy: 0.5652\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4324 - accuracy: 0.8593 - val_loss: 0.6900 - val_accuracy: 0.5652\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4286 - accuracy: 0.8593 - val_loss: 0.6675 - val_accuracy: 0.5652\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4214 - accuracy: 0.8794 - val_loss: 0.6645 - val_accuracy: 0.6087\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4089 - accuracy: 0.8794 - val_loss: 0.6529 - val_accuracy: 0.6087\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4009 - accuracy: 0.8794 - val_loss: 0.6613 - val_accuracy: 0.6087\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3950 - accuracy: 0.8945 - val_loss: 0.6634 - val_accuracy: 0.6087\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3902 - accuracy: 0.8844 - val_loss: 0.6358 - val_accuracy: 0.6522\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3849 - accuracy: 0.8794 - val_loss: 0.6444 - val_accuracy: 0.6087\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3751 - accuracy: 0.9045 - val_loss: 0.5946 - val_accuracy: 0.6522\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3818 - accuracy: 0.8744 - val_loss: 0.6466 - val_accuracy: 0.5652\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3660 - accuracy: 0.8995 - val_loss: 0.5961 - val_accuracy: 0.6087\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3686 - accuracy: 0.8945 - val_loss: 0.6556 - val_accuracy: 0.5652\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3545 - accuracy: 0.9146 - val_loss: 0.6540 - val_accuracy: 0.6087\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3655 - accuracy: 0.8794 - val_loss: 0.6352 - val_accuracy: 0.6087\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3604 - accuracy: 0.8794 - val_loss: 0.6477 - val_accuracy: 0.6087\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3533 - accuracy: 0.8894 - val_loss: 0.6450 - val_accuracy: 0.6087\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3475 - accuracy: 0.8945 - val_loss: 0.6326 - val_accuracy: 0.6087\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3408 - accuracy: 0.9045 - val_loss: 0.6003 - val_accuracy: 0.6522\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3326 - accuracy: 0.9095 - val_loss: 0.6466 - val_accuracy: 0.5652\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3280 - accuracy: 0.9146 - val_loss: 0.6168 - val_accuracy: 0.6087\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3223 - accuracy: 0.9196 - val_loss: 0.6093 - val_accuracy: 0.6522\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3234 - accuracy: 0.9095 - val_loss: 0.6150 - val_accuracy: 0.6522\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3114 - accuracy: 0.9246 - val_loss: 0.6618 - val_accuracy: 0.5652\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3143 - accuracy: 0.9095 - val_loss: 0.6642 - val_accuracy: 0.5652\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3140 - accuracy: 0.9146 - val_loss: 0.6451 - val_accuracy: 0.6087\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3180 - accuracy: 0.9246 - val_loss: 0.6323 - val_accuracy: 0.5652\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3054 - accuracy: 0.9296 - val_loss: 0.5872 - val_accuracy: 0.6957\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3141 - accuracy: 0.9196 - val_loss: 0.6564 - val_accuracy: 0.5652\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3109 - accuracy: 0.9146 - val_loss: 0.6269 - val_accuracy: 0.6087\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2973 - accuracy: 0.9296 - val_loss: 0.6092 - val_accuracy: 0.6957\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2999 - accuracy: 0.9246 - val_loss: 0.6340 - val_accuracy: 0.6087\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2889 - accuracy: 0.9347 - val_loss: 0.6676 - val_accuracy: 0.6087\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2971 - accuracy: 0.9246 - val_loss: 0.6780 - val_accuracy: 0.5652\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.2810 - accuracy: 0.9246 - val_loss: 0.6421 - val_accuracy: 0.6087\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2792 - accuracy: 0.9246 - val_loss: 0.6149 - val_accuracy: 0.6522\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2780 - accuracy: 0.9246 - val_loss: 0.6929 - val_accuracy: 0.5652\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2845 - accuracy: 0.9246 - val_loss: 0.6741 - val_accuracy: 0.6087\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2799 - accuracy: 0.9246 - val_loss: 0.5206 - val_accuracy: 0.7391\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.3300 - accuracy: 0.8794 - val_loss: 0.5328 - val_accuracy: 0.7391\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3088 - accuracy: 0.9045 - val_loss: 0.6544 - val_accuracy: 0.6522\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2976 - accuracy: 0.9045 - val_loss: 0.6389 - val_accuracy: 0.6522\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2914 - accuracy: 0.9146 - val_loss: 0.6294 - val_accuracy: 0.6522\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2894 - accuracy: 0.9095 - val_loss: 0.6486 - val_accuracy: 0.6087\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2735 - accuracy: 0.9296 - val_loss: 0.6331 - val_accuracy: 0.6957\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2666 - accuracy: 0.9397 - val_loss: 0.6616 - val_accuracy: 0.6087\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.2620 - accuracy: 0.9397 - val_loss: 0.5833 - val_accuracy: 0.6957\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2645 - accuracy: 0.9246 - val_loss: 0.6486 - val_accuracy: 0.6522\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2666 - accuracy: 0.9196 - val_loss: 0.6586 - val_accuracy: 0.6522\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2713 - accuracy: 0.9146 - val_loss: 0.6562 - val_accuracy: 0.6522\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2638 - accuracy: 0.9196 - val_loss: 0.6546 - val_accuracy: 0.6522\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.2588 - accuracy: 0.9296 - val_loss: 0.6581 - val_accuracy: 0.6522\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2520 - accuracy: 0.9296 - val_loss: 0.6466 - val_accuracy: 0.6522\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2446 - accuracy: 0.9347 - val_loss: 0.6483 - val_accuracy: 0.6522\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2342 - accuracy: 0.9598 - val_loss: 0.6490 - val_accuracy: 0.6522\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 4s 584ms/step - loss: 0.7107 - accuracy: 0.4824 - val_loss: 0.8118 - val_accuracy: 0.4348\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.7051 - accuracy: 0.5327 - val_loss: 0.7857 - val_accuracy: 0.4783\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6923 - accuracy: 0.5327 - val_loss: 0.7064 - val_accuracy: 0.4783\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6688 - accuracy: 0.5930 - val_loss: 0.6989 - val_accuracy: 0.5652\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6680 - accuracy: 0.6030 - val_loss: 0.7015 - val_accuracy: 0.5652\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6599 - accuracy: 0.6181 - val_loss: 0.7007 - val_accuracy: 0.5217\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6520 - accuracy: 0.6281 - val_loss: 0.7511 - val_accuracy: 0.4783\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6505 - accuracy: 0.6432 - val_loss: 0.7528 - val_accuracy: 0.4783\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6473 - accuracy: 0.6533 - val_loss: 0.7096 - val_accuracy: 0.4348\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6429 - accuracy: 0.6633 - val_loss: 0.7134 - val_accuracy: 0.4348\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6402 - accuracy: 0.6583 - val_loss: 0.7092 - val_accuracy: 0.4783\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6349 - accuracy: 0.6784 - val_loss: 0.6997 - val_accuracy: 0.6087\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6308 - accuracy: 0.6482 - val_loss: 0.6958 - val_accuracy: 0.6087\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6257 - accuracy: 0.6583 - val_loss: 0.6950 - val_accuracy: 0.6087\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6183 - accuracy: 0.6784 - val_loss: 0.6926 - val_accuracy: 0.6087\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6130 - accuracy: 0.7085 - val_loss: 0.7186 - val_accuracy: 0.5652\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6050 - accuracy: 0.7236 - val_loss: 0.7324 - val_accuracy: 0.5652\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6025 - accuracy: 0.7085 - val_loss: 0.7345 - val_accuracy: 0.5652\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5940 - accuracy: 0.7337 - val_loss: 0.7058 - val_accuracy: 0.5652\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5910 - accuracy: 0.7337 - val_loss: 0.6906 - val_accuracy: 0.5652\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5856 - accuracy: 0.7387 - val_loss: 0.7171 - val_accuracy: 0.5652\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5794 - accuracy: 0.7387 - val_loss: 0.7279 - val_accuracy: 0.5652\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5736 - accuracy: 0.7538 - val_loss: 0.7219 - val_accuracy: 0.5652\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5709 - accuracy: 0.7487 - val_loss: 0.7185 - val_accuracy: 0.6087\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5657 - accuracy: 0.7538 - val_loss: 0.7176 - val_accuracy: 0.6087\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5581 - accuracy: 0.7739 - val_loss: 0.7153 - val_accuracy: 0.6522\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5557 - accuracy: 0.7588 - val_loss: 0.7195 - val_accuracy: 0.6522\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5530 - accuracy: 0.7538 - val_loss: 0.7261 - val_accuracy: 0.6522\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5441 - accuracy: 0.7538 - val_loss: 0.7252 - val_accuracy: 0.6522\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5393 - accuracy: 0.7638 - val_loss: 0.7223 - val_accuracy: 0.6087\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5359 - accuracy: 0.7487 - val_loss: 0.7397 - val_accuracy: 0.5652\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5302 - accuracy: 0.7688 - val_loss: 0.7007 - val_accuracy: 0.6087\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5290 - accuracy: 0.7588 - val_loss: 0.7102 - val_accuracy: 0.6087\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5245 - accuracy: 0.7487 - val_loss: 0.7153 - val_accuracy: 0.6087\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5195 - accuracy: 0.7437 - val_loss: 0.7144 - val_accuracy: 0.6087\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5110 - accuracy: 0.7688 - val_loss: 0.7634 - val_accuracy: 0.5217\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5017 - accuracy: 0.7739 - val_loss: 0.7547 - val_accuracy: 0.5217\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4952 - accuracy: 0.7889 - val_loss: 0.7517 - val_accuracy: 0.5217\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4899 - accuracy: 0.7739 - val_loss: 0.7610 - val_accuracy: 0.5217\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4842 - accuracy: 0.7739 - val_loss: 0.7872 - val_accuracy: 0.5217\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4798 - accuracy: 0.7688 - val_loss: 0.7891 - val_accuracy: 0.4783\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4851 - accuracy: 0.7638 - val_loss: 0.7556 - val_accuracy: 0.5652\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4709 - accuracy: 0.7889 - val_loss: 0.7291 - val_accuracy: 0.5652\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4734 - accuracy: 0.7889 - val_loss: 0.7405 - val_accuracy: 0.5217\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4604 - accuracy: 0.8040 - val_loss: 0.7480 - val_accuracy: 0.5217\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4545 - accuracy: 0.8040 - val_loss: 0.7226 - val_accuracy: 0.4783\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4535 - accuracy: 0.7990 - val_loss: 0.7580 - val_accuracy: 0.4783\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4454 - accuracy: 0.8141 - val_loss: 0.7322 - val_accuracy: 0.5652\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4432 - accuracy: 0.8141 - val_loss: 0.7402 - val_accuracy: 0.5217\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4366 - accuracy: 0.8241 - val_loss: 0.7548 - val_accuracy: 0.5217\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4366 - accuracy: 0.8241 - val_loss: 0.7345 - val_accuracy: 0.5652\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.4328 - accuracy: 0.8291 - val_loss: 0.7477 - val_accuracy: 0.5217\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4217 - accuracy: 0.8291 - val_loss: 0.7552 - val_accuracy: 0.4348\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4127 - accuracy: 0.8392 - val_loss: 0.7484 - val_accuracy: 0.5217\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4115 - accuracy: 0.8241 - val_loss: 0.7783 - val_accuracy: 0.5217\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4019 - accuracy: 0.8241 - val_loss: 0.7744 - val_accuracy: 0.5217\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4025 - accuracy: 0.8442 - val_loss: 0.7234 - val_accuracy: 0.6087\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3920 - accuracy: 0.8392 - val_loss: 0.7218 - val_accuracy: 0.6087\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3860 - accuracy: 0.8492 - val_loss: 0.7078 - val_accuracy: 0.6087\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3841 - accuracy: 0.8492 - val_loss: 0.7370 - val_accuracy: 0.5217\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3787 - accuracy: 0.8543 - val_loss: 0.7324 - val_accuracy: 0.5217\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3731 - accuracy: 0.8442 - val_loss: 0.6871 - val_accuracy: 0.6087\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 0.3642 - accuracy: 0.85 - 0s 35ms/step - loss: 0.3785 - accuracy: 0.8342 - val_loss: 0.6971 - val_accuracy: 0.6087\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.3674 - accuracy: 0.8593 - val_loss: 0.8081 - val_accuracy: 0.5217\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3743 - accuracy: 0.8643 - val_loss: 0.6785 - val_accuracy: 0.6087\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.3783 - accuracy: 0.8593 - val_loss: 0.7166 - val_accuracy: 0.6087\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3683 - accuracy: 0.8643 - val_loss: 0.7724 - val_accuracy: 0.5217\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3716 - accuracy: 0.8543 - val_loss: 0.6294 - val_accuracy: 0.5652\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3705 - accuracy: 0.8392 - val_loss: 0.6861 - val_accuracy: 0.6087\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3768 - accuracy: 0.8492 - val_loss: 0.7017 - val_accuracy: 0.6087\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3670 - accuracy: 0.8593 - val_loss: 0.6906 - val_accuracy: 0.5652\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3596 - accuracy: 0.8643 - val_loss: 0.6763 - val_accuracy: 0.5652\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3467 - accuracy: 0.8744 - val_loss: 0.6735 - val_accuracy: 0.5652\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3452 - accuracy: 0.8693 - val_loss: 0.7536 - val_accuracy: 0.6522\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3457 - accuracy: 0.8693 - val_loss: 0.7727 - val_accuracy: 0.5652\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3585 - accuracy: 0.8492 - val_loss: 0.7240 - val_accuracy: 0.5652\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3738 - accuracy: 0.8543 - val_loss: 0.6759 - val_accuracy: 0.6087\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4038 - accuracy: 0.8191 - val_loss: 0.6687 - val_accuracy: 0.5652\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3810 - accuracy: 0.8342 - val_loss: 0.7220 - val_accuracy: 0.5652\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3533 - accuracy: 0.8442 - val_loss: 0.7132 - val_accuracy: 0.6087\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3721 - accuracy: 0.8342 - val_loss: 0.7347 - val_accuracy: 0.5652\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3743 - accuracy: 0.8342 - val_loss: 0.6993 - val_accuracy: 0.6087\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3439 - accuracy: 0.8593 - val_loss: 0.6827 - val_accuracy: 0.6087\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3499 - accuracy: 0.8643 - val_loss: 0.6700 - val_accuracy: 0.5217\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3346 - accuracy: 0.8593 - val_loss: 0.6684 - val_accuracy: 0.6087\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3227 - accuracy: 0.8593 - val_loss: 0.6595 - val_accuracy: 0.6957\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3223 - accuracy: 0.8844 - val_loss: 0.6776 - val_accuracy: 0.6522\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3194 - accuracy: 0.8794 - val_loss: 0.6537 - val_accuracy: 0.6957\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3007 - accuracy: 0.8794 - val_loss: 0.6729 - val_accuracy: 0.6957\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2899 - accuracy: 0.8844 - val_loss: 0.6902 - val_accuracy: 0.6522\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2850 - accuracy: 0.8844 - val_loss: 0.7159 - val_accuracy: 0.6522\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2790 - accuracy: 0.8794 - val_loss: 0.7188 - val_accuracy: 0.6522\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2862 - accuracy: 0.8894 - val_loss: 0.7281 - val_accuracy: 0.6522\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3356 - accuracy: 0.8442 - val_loss: 0.7895 - val_accuracy: 0.6087\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3278 - accuracy: 0.8442 - val_loss: 0.7561 - val_accuracy: 0.6087\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3047 - accuracy: 0.8844 - val_loss: 0.6999 - val_accuracy: 0.7391\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2832 - accuracy: 0.8844 - val_loss: 0.6765 - val_accuracy: 0.7391\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.2748 - accuracy: 0.8794 - val_loss: 0.6952 - val_accuracy: 0.7391\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.2623 - accuracy: 0.8894 - val_loss: 0.7174 - val_accuracy: 0.6957\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.2641 - accuracy: 0.8844 - val_loss: 0.7282 - val_accuracy: 0.6522\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 3s 640ms/step - loss: 0.7796 - accuracy: 0.4925 - val_loss: 0.7294 - val_accuracy: 0.5652\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.7375 - accuracy: 0.4925 - val_loss: 0.6974 - val_accuracy: 0.5652\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.7150 - accuracy: 0.4874 - val_loss: 0.6850 - val_accuracy: 0.5652\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6924 - accuracy: 0.5025 - val_loss: 0.6839 - val_accuracy: 0.6087\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6759 - accuracy: 0.5327 - val_loss: 0.6896 - val_accuracy: 0.6087\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6651 - accuracy: 0.6080 - val_loss: 0.7018 - val_accuracy: 0.6522\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6588 - accuracy: 0.6231 - val_loss: 0.7096 - val_accuracy: 0.5652\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6543 - accuracy: 0.6382 - val_loss: 0.7090 - val_accuracy: 0.4783\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6460 - accuracy: 0.6432 - val_loss: 0.6991 - val_accuracy: 0.4783\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6362 - accuracy: 0.6633 - val_loss: 0.6854 - val_accuracy: 0.5652\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6280 - accuracy: 0.6884 - val_loss: 0.6720 - val_accuracy: 0.6087\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6198 - accuracy: 0.6834 - val_loss: 0.6587 - val_accuracy: 0.6957\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6124 - accuracy: 0.6734 - val_loss: 0.6453 - val_accuracy: 0.6522\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6053 - accuracy: 0.6683 - val_loss: 0.6360 - val_accuracy: 0.6957\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5990 - accuracy: 0.6884 - val_loss: 0.6297 - val_accuracy: 0.7391\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5887 - accuracy: 0.7035 - val_loss: 0.6276 - val_accuracy: 0.7391\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5811 - accuracy: 0.7186 - val_loss: 0.6327 - val_accuracy: 0.6957\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5744 - accuracy: 0.7387 - val_loss: 0.6326 - val_accuracy: 0.6957\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5675 - accuracy: 0.7387 - val_loss: 0.6236 - val_accuracy: 0.6957\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5608 - accuracy: 0.7387 - val_loss: 0.6144 - val_accuracy: 0.7391\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5559 - accuracy: 0.7236 - val_loss: 0.6105 - val_accuracy: 0.7391\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5492 - accuracy: 0.7538 - val_loss: 0.6070 - val_accuracy: 0.7826\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5425 - accuracy: 0.7588 - val_loss: 0.6026 - val_accuracy: 0.7391\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5349 - accuracy: 0.7638 - val_loss: 0.6015 - val_accuracy: 0.7391\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5301 - accuracy: 0.7789 - val_loss: 0.6011 - val_accuracy: 0.6957\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5216 - accuracy: 0.7839 - val_loss: 0.6038 - val_accuracy: 0.6957\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5174 - accuracy: 0.7789 - val_loss: 0.6053 - val_accuracy: 0.7391\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5073 - accuracy: 0.7839 - val_loss: 0.6034 - val_accuracy: 0.6957\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.5011 - accuracy: 0.7889 - val_loss: 0.6001 - val_accuracy: 0.6957\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.4948 - accuracy: 0.8040 - val_loss: 0.5895 - val_accuracy: 0.6957\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4859 - accuracy: 0.8040 - val_loss: 0.5791 - val_accuracy: 0.6957\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4795 - accuracy: 0.8040 - val_loss: 0.5643 - val_accuracy: 0.6957\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4722 - accuracy: 0.8141 - val_loss: 0.5572 - val_accuracy: 0.6957\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4663 - accuracy: 0.7990 - val_loss: 0.5596 - val_accuracy: 0.6957\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4601 - accuracy: 0.8141 - val_loss: 0.5727 - val_accuracy: 0.6957\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4513 - accuracy: 0.8241 - val_loss: 0.5783 - val_accuracy: 0.6957\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4440 - accuracy: 0.8342 - val_loss: 0.5704 - val_accuracy: 0.6957\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4389 - accuracy: 0.8342 - val_loss: 0.5673 - val_accuracy: 0.6957\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4339 - accuracy: 0.8241 - val_loss: 0.5698 - val_accuracy: 0.6522\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.4242 - accuracy: 0.8342 - val_loss: 0.5780 - val_accuracy: 0.6957\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4239 - accuracy: 0.8342 - val_loss: 0.5770 - val_accuracy: 0.6957\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4118 - accuracy: 0.8342 - val_loss: 0.5766 - val_accuracy: 0.6522\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4115 - accuracy: 0.8241 - val_loss: 0.5584 - val_accuracy: 0.6522\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3970 - accuracy: 0.8543 - val_loss: 0.5726 - val_accuracy: 0.6957\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3965 - accuracy: 0.8392 - val_loss: 0.5805 - val_accuracy: 0.6522\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3830 - accuracy: 0.8593 - val_loss: 0.5936 - val_accuracy: 0.6522\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3810 - accuracy: 0.8744 - val_loss: 0.6028 - val_accuracy: 0.6522\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3735 - accuracy: 0.8794 - val_loss: 0.6077 - val_accuracy: 0.6957\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3674 - accuracy: 0.8744 - val_loss: 0.5929 - val_accuracy: 0.6522\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3598 - accuracy: 0.8643 - val_loss: 0.5895 - val_accuracy: 0.6522\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3532 - accuracy: 0.8643 - val_loss: 0.5803 - val_accuracy: 0.6957\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3450 - accuracy: 0.8693 - val_loss: 0.5826 - val_accuracy: 0.6957\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3408 - accuracy: 0.8844 - val_loss: 0.5805 - val_accuracy: 0.6522\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3329 - accuracy: 0.8844 - val_loss: 0.5838 - val_accuracy: 0.6522\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3200 - accuracy: 0.8995 - val_loss: 0.5881 - val_accuracy: 0.6522\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3182 - accuracy: 0.8945 - val_loss: 0.5826 - val_accuracy: 0.6522\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3162 - accuracy: 0.8995 - val_loss: 0.5501 - val_accuracy: 0.6522\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3057 - accuracy: 0.8945 - val_loss: 0.5607 - val_accuracy: 0.6957\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3012 - accuracy: 0.9095 - val_loss: 0.5786 - val_accuracy: 0.6522\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.2903 - accuracy: 0.9146 - val_loss: 0.5883 - val_accuracy: 0.6957\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2888 - accuracy: 0.9196 - val_loss: 0.5899 - val_accuracy: 0.6957\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.2809 - accuracy: 0.9146 - val_loss: 0.5684 - val_accuracy: 0.6957\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2796 - accuracy: 0.8995 - val_loss: 0.5420 - val_accuracy: 0.6957\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2699 - accuracy: 0.9146 - val_loss: 0.5650 - val_accuracy: 0.6957\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2687 - accuracy: 0.9246 - val_loss: 0.6110 - val_accuracy: 0.7391\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2607 - accuracy: 0.9246 - val_loss: 0.6225 - val_accuracy: 0.7391\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2633 - accuracy: 0.9146 - val_loss: 0.5713 - val_accuracy: 0.6957\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2556 - accuracy: 0.9246 - val_loss: 0.5686 - val_accuracy: 0.6957\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.2468 - accuracy: 0.9397 - val_loss: 0.6089 - val_accuracy: 0.7391\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.2473 - accuracy: 0.9246 - val_loss: 0.6087 - val_accuracy: 0.7826\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2382 - accuracy: 0.9397 - val_loss: 0.5777 - val_accuracy: 0.6957\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.2360 - accuracy: 0.9497 - val_loss: 0.5770 - val_accuracy: 0.6957\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2317 - accuracy: 0.9497 - val_loss: 0.5945 - val_accuracy: 0.7826\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2249 - accuracy: 0.9397 - val_loss: 0.6004 - val_accuracy: 0.7391\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2221 - accuracy: 0.9497 - val_loss: 0.6138 - val_accuracy: 0.6957\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2182 - accuracy: 0.9497 - val_loss: 0.6253 - val_accuracy: 0.6522\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2137 - accuracy: 0.9497 - val_loss: 0.6081 - val_accuracy: 0.6522\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2073 - accuracy: 0.9548 - val_loss: 0.5726 - val_accuracy: 0.6522\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.2042 - accuracy: 0.9548 - val_loss: 0.6066 - val_accuracy: 0.6522\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1970 - accuracy: 0.9648 - val_loss: 0.6505 - val_accuracy: 0.6957\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1979 - accuracy: 0.9648 - val_loss: 0.6397 - val_accuracy: 0.6522\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1906 - accuracy: 0.9648 - val_loss: 0.6101 - val_accuracy: 0.6522\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1864 - accuracy: 0.9648 - val_loss: 0.5713 - val_accuracy: 0.6522\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1842 - accuracy: 0.9598 - val_loss: 0.5764 - val_accuracy: 0.6522\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1829 - accuracy: 0.9598 - val_loss: 0.6275 - val_accuracy: 0.6522\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1768 - accuracy: 0.9698 - val_loss: 0.6445 - val_accuracy: 0.6522\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1752 - accuracy: 0.9698 - val_loss: 0.6256 - val_accuracy: 0.6522\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1712 - accuracy: 0.9698 - val_loss: 0.5765 - val_accuracy: 0.6957\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1703 - accuracy: 0.9648 - val_loss: 0.5671 - val_accuracy: 0.6522\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.1636 - accuracy: 0.9648 - val_loss: 0.6049 - val_accuracy: 0.6522\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.1632 - accuracy: 0.9749 - val_loss: 0.6301 - val_accuracy: 0.6522\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1583 - accuracy: 0.9698 - val_loss: 0.6290 - val_accuracy: 0.6957\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1577 - accuracy: 0.9648 - val_loss: 0.5693 - val_accuracy: 0.7391\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1524 - accuracy: 0.9698 - val_loss: 0.5449 - val_accuracy: 0.7391\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.1498 - accuracy: 0.9698 - val_loss: 0.5708 - val_accuracy: 0.6957\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1466 - accuracy: 0.9698 - val_loss: 0.6081 - val_accuracy: 0.6957\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1433 - accuracy: 0.9749 - val_loss: 0.6081 - val_accuracy: 0.6957\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.1410 - accuracy: 0.9749 - val_loss: 0.6024 - val_accuracy: 0.6957\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.1400 - accuracy: 0.9648 - val_loss: 0.5805 - val_accuracy: 0.6957\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1345 - accuracy: 0.9698 - val_loss: 0.6017 - val_accuracy: 0.6957\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 3s 624ms/step - loss: 0.8418 - accuracy: 0.4724 - val_loss: 0.7830 - val_accuracy: 0.5217\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 73ms/step - loss: 0.7561 - accuracy: 0.5427 - val_loss: 0.7015 - val_accuracy: 0.5652\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.7180 - accuracy: 0.5427 - val_loss: 0.6868 - val_accuracy: 0.5217\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6945 - accuracy: 0.5628 - val_loss: 0.6646 - val_accuracy: 0.5652\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6708 - accuracy: 0.6030 - val_loss: 0.7135 - val_accuracy: 0.6087\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6521 - accuracy: 0.6231 - val_loss: 0.7359 - val_accuracy: 0.5217\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6539 - accuracy: 0.5678 - val_loss: 0.7407 - val_accuracy: 0.4783\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6416 - accuracy: 0.5980 - val_loss: 0.7314 - val_accuracy: 0.4783\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6160 - accuracy: 0.6683 - val_loss: 0.6918 - val_accuracy: 0.5217\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6141 - accuracy: 0.6633 - val_loss: 0.6726 - val_accuracy: 0.5652\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.6128 - accuracy: 0.6432 - val_loss: 0.6724 - val_accuracy: 0.6522\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6041 - accuracy: 0.6683 - val_loss: 0.6878 - val_accuracy: 0.6522\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5975 - accuracy: 0.6985 - val_loss: 0.6838 - val_accuracy: 0.7391\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5880 - accuracy: 0.7035 - val_loss: 0.6841 - val_accuracy: 0.5652\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5631 - accuracy: 0.7487 - val_loss: 0.6775 - val_accuracy: 0.6087\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5596 - accuracy: 0.6985 - val_loss: 0.6929 - val_accuracy: 0.4783\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5527 - accuracy: 0.7035 - val_loss: 0.7040 - val_accuracy: 0.5217\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5456 - accuracy: 0.7487 - val_loss: 0.6965 - val_accuracy: 0.5652\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5314 - accuracy: 0.7437 - val_loss: 0.7523 - val_accuracy: 0.4783\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5256 - accuracy: 0.7638 - val_loss: 0.7127 - val_accuracy: 0.5652\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5294 - accuracy: 0.7739 - val_loss: 0.6797 - val_accuracy: 0.6522\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5137 - accuracy: 0.7789 - val_loss: 0.7156 - val_accuracy: 0.5217\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4987 - accuracy: 0.7789 - val_loss: 0.6935 - val_accuracy: 0.5217\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4980 - accuracy: 0.7789 - val_loss: 0.6717 - val_accuracy: 0.6522\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4816 - accuracy: 0.7990 - val_loss: 0.6386 - val_accuracy: 0.6957\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4768 - accuracy: 0.8090 - val_loss: 0.6356 - val_accuracy: 0.7391\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4665 - accuracy: 0.8090 - val_loss: 0.6163 - val_accuracy: 0.7391\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4688 - accuracy: 0.8040 - val_loss: 0.6079 - val_accuracy: 0.7826\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.4636 - accuracy: 0.7889 - val_loss: 0.6263 - val_accuracy: 0.6957\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.4429 - accuracy: 0.8090 - val_loss: 0.6250 - val_accuracy: 0.7391\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4300 - accuracy: 0.8291 - val_loss: 0.5807 - val_accuracy: 0.7826\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4504 - accuracy: 0.7990 - val_loss: 0.5752 - val_accuracy: 0.7391\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4269 - accuracy: 0.8543 - val_loss: 0.5930 - val_accuracy: 0.7391\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4241 - accuracy: 0.8442 - val_loss: 0.6078 - val_accuracy: 0.7391\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4143 - accuracy: 0.8492 - val_loss: 0.5961 - val_accuracy: 0.7391\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4013 - accuracy: 0.8593 - val_loss: 0.5825 - val_accuracy: 0.7391\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.3907 - accuracy: 0.8593 - val_loss: 0.5938 - val_accuracy: 0.7826\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 68ms/step - loss: 0.3850 - accuracy: 0.8543 - val_loss: 0.6103 - val_accuracy: 0.7391\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.3782 - accuracy: 0.8744 - val_loss: 0.6136 - val_accuracy: 0.7391\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3973 - accuracy: 0.8643 - val_loss: 0.5811 - val_accuracy: 0.7826\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3658 - accuracy: 0.8844 - val_loss: 0.6086 - val_accuracy: 0.7391\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3759 - accuracy: 0.8744 - val_loss: 0.5837 - val_accuracy: 0.7391\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.3567 - accuracy: 0.8844 - val_loss: 0.5843 - val_accuracy: 0.7391\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3489 - accuracy: 0.8794 - val_loss: 0.6100 - val_accuracy: 0.7391\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3399 - accuracy: 0.9095 - val_loss: 0.5892 - val_accuracy: 0.7826\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.3418 - accuracy: 0.9095 - val_loss: 0.5942 - val_accuracy: 0.8261\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3303 - accuracy: 0.9196 - val_loss: 0.6428 - val_accuracy: 0.6957\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3366 - accuracy: 0.8995 - val_loss: 0.5839 - val_accuracy: 0.8261\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.3235 - accuracy: 0.8945 - val_loss: 0.5762 - val_accuracy: 0.7826\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.3098 - accuracy: 0.9146 - val_loss: 0.5870 - val_accuracy: 0.7391\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3098 - accuracy: 0.9045 - val_loss: 0.5838 - val_accuracy: 0.7391\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.3056 - accuracy: 0.9095 - val_loss: 0.5635 - val_accuracy: 0.7826\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.2916 - accuracy: 0.9397 - val_loss: 0.5497 - val_accuracy: 0.8261\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.2837 - accuracy: 0.9397 - val_loss: 0.5311 - val_accuracy: 0.8261\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.2802 - accuracy: 0.9296 - val_loss: 0.5392 - val_accuracy: 0.7826\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.2768 - accuracy: 0.9296 - val_loss: 0.5538 - val_accuracy: 0.8261\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.2699 - accuracy: 0.9397 - val_loss: 0.5640 - val_accuracy: 0.7826\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.2566 - accuracy: 0.9397 - val_loss: 0.5501 - val_accuracy: 0.8261\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.2580 - accuracy: 0.9347 - val_loss: 0.5403 - val_accuracy: 0.7826\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.2553 - accuracy: 0.9447 - val_loss: 0.5543 - val_accuracy: 0.7826\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.2522 - accuracy: 0.9347 - val_loss: 0.5421 - val_accuracy: 0.7826\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2396 - accuracy: 0.9447 - val_loss: 0.5610 - val_accuracy: 0.7826\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2316 - accuracy: 0.9598 - val_loss: 0.5686 - val_accuracy: 0.7391\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.2256 - accuracy: 0.9548 - val_loss: 0.5616 - val_accuracy: 0.7391\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.2189 - accuracy: 0.9548 - val_loss: 0.5726 - val_accuracy: 0.7391\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.2139 - accuracy: 0.9548 - val_loss: 0.5842 - val_accuracy: 0.7391\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.2069 - accuracy: 0.9598 - val_loss: 0.5952 - val_accuracy: 0.7391\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.2001 - accuracy: 0.9648 - val_loss: 0.5938 - val_accuracy: 0.6957\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.1962 - accuracy: 0.9648 - val_loss: 0.5840 - val_accuracy: 0.7391\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.1898 - accuracy: 0.9598 - val_loss: 0.5939 - val_accuracy: 0.7391\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1864 - accuracy: 0.9598 - val_loss: 0.5822 - val_accuracy: 0.7391\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.1838 - accuracy: 0.9598 - val_loss: 0.5794 - val_accuracy: 0.7391\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.1783 - accuracy: 0.9648 - val_loss: 0.5834 - val_accuracy: 0.7391\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1749 - accuracy: 0.9648 - val_loss: 0.6101 - val_accuracy: 0.7391\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.1732 - accuracy: 0.9648 - val_loss: 0.6019 - val_accuracy: 0.7391\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.1662 - accuracy: 0.9648 - val_loss: 0.6070 - val_accuracy: 0.7391\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.1647 - accuracy: 0.9648 - val_loss: 0.5859 - val_accuracy: 0.7391\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.1720 - accuracy: 0.9598 - val_loss: 0.6149 - val_accuracy: 0.7391\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.1840 - accuracy: 0.9648 - val_loss: 0.6669 - val_accuracy: 0.7391\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.1958 - accuracy: 0.9548 - val_loss: 0.6329 - val_accuracy: 0.7826\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.1738 - accuracy: 0.9548 - val_loss: 0.5652 - val_accuracy: 0.7826\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.2215 - accuracy: 0.9397 - val_loss: 0.5423 - val_accuracy: 0.7826\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.2240 - accuracy: 0.9246 - val_loss: 0.6702 - val_accuracy: 0.6957\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.2561 - accuracy: 0.9196 - val_loss: 0.7127 - val_accuracy: 0.6957\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.2270 - accuracy: 0.9246 - val_loss: 0.7138 - val_accuracy: 0.7391\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.2317 - accuracy: 0.9246 - val_loss: 0.6816 - val_accuracy: 0.7391\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.2207 - accuracy: 0.9397 - val_loss: 0.6557 - val_accuracy: 0.6957\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 63ms/step - loss: 0.2099 - accuracy: 0.9397 - val_loss: 0.6161 - val_accuracy: 0.7391\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.2024 - accuracy: 0.9397 - val_loss: 0.6952 - val_accuracy: 0.7391\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.2046 - accuracy: 0.9347 - val_loss: 0.6543 - val_accuracy: 0.7826\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.1939 - accuracy: 0.9447 - val_loss: 0.7529 - val_accuracy: 0.6522\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.1830 - accuracy: 0.9497 - val_loss: 0.7646 - val_accuracy: 0.7391\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.1848 - accuracy: 0.9447 - val_loss: 0.7773 - val_accuracy: 0.6522\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.1707 - accuracy: 0.9548 - val_loss: 0.7666 - val_accuracy: 0.6522\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.1586 - accuracy: 0.9548 - val_loss: 0.8212 - val_accuracy: 0.6957\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1539 - accuracy: 0.9648 - val_loss: 0.7897 - val_accuracy: 0.7391\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1725 - accuracy: 0.9548 - val_loss: 0.7682 - val_accuracy: 0.7391\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.1599 - accuracy: 0.9548 - val_loss: 0.7151 - val_accuracy: 0.7826\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.1791 - accuracy: 0.9397 - val_loss: 0.7696 - val_accuracy: 0.6522\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.1534 - accuracy: 0.9598 - val_loss: 0.7807 - val_accuracy: 0.6957\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 2s 489ms/step - loss: 0.7025 - accuracy: 0.4774 - val_loss: 0.6771 - val_accuracy: 0.5652\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6958 - accuracy: 0.4925 - val_loss: 0.6761 - val_accuracy: 0.6522\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6909 - accuracy: 0.5126 - val_loss: 0.6750 - val_accuracy: 0.6522\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6876 - accuracy: 0.5075 - val_loss: 0.6746 - val_accuracy: 0.6087\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6844 - accuracy: 0.5327 - val_loss: 0.6749 - val_accuracy: 0.6522\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6818 - accuracy: 0.5729 - val_loss: 0.6762 - val_accuracy: 0.6957\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6793 - accuracy: 0.5829 - val_loss: 0.6776 - val_accuracy: 0.6957\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6770 - accuracy: 0.6131 - val_loss: 0.6787 - val_accuracy: 0.6087\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6748 - accuracy: 0.6281 - val_loss: 0.6793 - val_accuracy: 0.5652\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6725 - accuracy: 0.6231 - val_loss: 0.6792 - val_accuracy: 0.5652\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6702 - accuracy: 0.6231 - val_loss: 0.6784 - val_accuracy: 0.6087\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6677 - accuracy: 0.6231 - val_loss: 0.6775 - val_accuracy: 0.6087\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.6650 - accuracy: 0.6181 - val_loss: 0.6761 - val_accuracy: 0.6087\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.6621 - accuracy: 0.6332 - val_loss: 0.6750 - val_accuracy: 0.6522\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6589 - accuracy: 0.6583 - val_loss: 0.6740 - val_accuracy: 0.6522\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.6560 - accuracy: 0.6683 - val_loss: 0.6732 - val_accuracy: 0.6522\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.6527 - accuracy: 0.6683 - val_loss: 0.6719 - val_accuracy: 0.6522\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.6499 - accuracy: 0.6633 - val_loss: 0.6706 - val_accuracy: 0.6522\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.6465 - accuracy: 0.6683 - val_loss: 0.6682 - val_accuracy: 0.6522\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6433 - accuracy: 0.6784 - val_loss: 0.6657 - val_accuracy: 0.6522\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6401 - accuracy: 0.6633 - val_loss: 0.6633 - val_accuracy: 0.6522\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.6371 - accuracy: 0.6834 - val_loss: 0.6602 - val_accuracy: 0.6087\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 64ms/step - loss: 0.6340 - accuracy: 0.6834 - val_loss: 0.6570 - val_accuracy: 0.6087\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.6314 - accuracy: 0.6784 - val_loss: 0.6537 - val_accuracy: 0.6087\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 83ms/step - loss: 0.6284 - accuracy: 0.6884 - val_loss: 0.6511 - val_accuracy: 0.6087\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 71ms/step - loss: 0.6262 - accuracy: 0.6985 - val_loss: 0.6498 - val_accuracy: 0.6087\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.6237 - accuracy: 0.6985 - val_loss: 0.6497 - val_accuracy: 0.6087\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6214 - accuracy: 0.7085 - val_loss: 0.6507 - val_accuracy: 0.6087\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6185 - accuracy: 0.7085 - val_loss: 0.6515 - val_accuracy: 0.6087\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6164 - accuracy: 0.7136 - val_loss: 0.6508 - val_accuracy: 0.6087\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.6142 - accuracy: 0.7085 - val_loss: 0.6494 - val_accuracy: 0.6087\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6117 - accuracy: 0.7035 - val_loss: 0.6484 - val_accuracy: 0.6522\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6096 - accuracy: 0.7085 - val_loss: 0.6494 - val_accuracy: 0.6522\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6069 - accuracy: 0.7085 - val_loss: 0.6513 - val_accuracy: 0.6087\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.6046 - accuracy: 0.7085 - val_loss: 0.6546 - val_accuracy: 0.5652\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6019 - accuracy: 0.7035 - val_loss: 0.6568 - val_accuracy: 0.5652\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6001 - accuracy: 0.6935 - val_loss: 0.6587 - val_accuracy: 0.5652\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5976 - accuracy: 0.6985 - val_loss: 0.6591 - val_accuracy: 0.5652\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5950 - accuracy: 0.7035 - val_loss: 0.6573 - val_accuracy: 0.5652\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5927 - accuracy: 0.6985 - val_loss: 0.6588 - val_accuracy: 0.5652\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5904 - accuracy: 0.7035 - val_loss: 0.6605 - val_accuracy: 0.5652\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5876 - accuracy: 0.7035 - val_loss: 0.6604 - val_accuracy: 0.5652\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5852 - accuracy: 0.7085 - val_loss: 0.6611 - val_accuracy: 0.5652\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5821 - accuracy: 0.7136 - val_loss: 0.6646 - val_accuracy: 0.5652\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.5799 - accuracy: 0.7136 - val_loss: 0.6699 - val_accuracy: 0.5217\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5764 - accuracy: 0.7186 - val_loss: 0.6745 - val_accuracy: 0.5217\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5738 - accuracy: 0.7236 - val_loss: 0.6769 - val_accuracy: 0.5217\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5717 - accuracy: 0.7286 - val_loss: 0.6792 - val_accuracy: 0.5217\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5692 - accuracy: 0.7236 - val_loss: 0.6816 - val_accuracy: 0.5217\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5668 - accuracy: 0.7236 - val_loss: 0.6811 - val_accuracy: 0.5217\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5645 - accuracy: 0.7286 - val_loss: 0.6807 - val_accuracy: 0.5217\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5614 - accuracy: 0.7286 - val_loss: 0.6804 - val_accuracy: 0.5217\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5591 - accuracy: 0.7286 - val_loss: 0.6825 - val_accuracy: 0.5652\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.5564 - accuracy: 0.7286 - val_loss: 0.6867 - val_accuracy: 0.5652\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.5537 - accuracy: 0.7387 - val_loss: 0.6895 - val_accuracy: 0.5652\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5505 - accuracy: 0.7337 - val_loss: 0.6915 - val_accuracy: 0.5652\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5472 - accuracy: 0.7387 - val_loss: 0.6934 - val_accuracy: 0.5652\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5443 - accuracy: 0.7337 - val_loss: 0.6953 - val_accuracy: 0.5652\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5420 - accuracy: 0.7337 - val_loss: 0.6986 - val_accuracy: 0.5652\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5390 - accuracy: 0.7337 - val_loss: 0.7007 - val_accuracy: 0.5652\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5361 - accuracy: 0.7286 - val_loss: 0.7040 - val_accuracy: 0.5652\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5336 - accuracy: 0.7286 - val_loss: 0.7076 - val_accuracy: 0.5652\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.5315 - accuracy: 0.7236 - val_loss: 0.7097 - val_accuracy: 0.5652\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5287 - accuracy: 0.7236 - val_loss: 0.7115 - val_accuracy: 0.5652\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.5261 - accuracy: 0.7337 - val_loss: 0.7113 - val_accuracy: 0.5652\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5241 - accuracy: 0.7387 - val_loss: 0.7101 - val_accuracy: 0.5652\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5220 - accuracy: 0.7387 - val_loss: 0.7086 - val_accuracy: 0.5652\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5190 - accuracy: 0.7337 - val_loss: 0.7084 - val_accuracy: 0.6087\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5169 - accuracy: 0.7337 - val_loss: 0.7112 - val_accuracy: 0.6087\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5149 - accuracy: 0.7337 - val_loss: 0.7139 - val_accuracy: 0.5652\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5124 - accuracy: 0.7437 - val_loss: 0.7155 - val_accuracy: 0.5652\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5104 - accuracy: 0.7487 - val_loss: 0.7166 - val_accuracy: 0.5652\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5091 - accuracy: 0.7538 - val_loss: 0.7151 - val_accuracy: 0.6087\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 60ms/step - loss: 0.5054 - accuracy: 0.7538 - val_loss: 0.7111 - val_accuracy: 0.6087\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 61ms/step - loss: 0.5031 - accuracy: 0.7437 - val_loss: 0.7070 - val_accuracy: 0.6087\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.5017 - accuracy: 0.7487 - val_loss: 0.7078 - val_accuracy: 0.6087\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4997 - accuracy: 0.7437 - val_loss: 0.7114 - val_accuracy: 0.6087\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 62ms/step - loss: 0.4970 - accuracy: 0.7538 - val_loss: 0.7138 - val_accuracy: 0.6087\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4942 - accuracy: 0.7588 - val_loss: 0.7162 - val_accuracy: 0.6087\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4927 - accuracy: 0.7588 - val_loss: 0.7186 - val_accuracy: 0.6087\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4899 - accuracy: 0.7638 - val_loss: 0.7173 - val_accuracy: 0.6087\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4871 - accuracy: 0.7588 - val_loss: 0.7151 - val_accuracy: 0.6087\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4849 - accuracy: 0.7638 - val_loss: 0.7149 - val_accuracy: 0.6087\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4825 - accuracy: 0.7638 - val_loss: 0.7165 - val_accuracy: 0.6087\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4804 - accuracy: 0.7739 - val_loss: 0.7171 - val_accuracy: 0.6087\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4777 - accuracy: 0.7789 - val_loss: 0.7181 - val_accuracy: 0.6087\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 54ms/step - loss: 0.4752 - accuracy: 0.7789 - val_loss: 0.7207 - val_accuracy: 0.6087\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4732 - accuracy: 0.7789 - val_loss: 0.7268 - val_accuracy: 0.6087\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4708 - accuracy: 0.7739 - val_loss: 0.7296 - val_accuracy: 0.6087\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4683 - accuracy: 0.7688 - val_loss: 0.7312 - val_accuracy: 0.6087\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4663 - accuracy: 0.7789 - val_loss: 0.7331 - val_accuracy: 0.6087\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4634 - accuracy: 0.7839 - val_loss: 0.7351 - val_accuracy: 0.6087\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.4614 - accuracy: 0.7739 - val_loss: 0.7367 - val_accuracy: 0.6087\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4590 - accuracy: 0.7789 - val_loss: 0.7370 - val_accuracy: 0.6087\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4565 - accuracy: 0.7889 - val_loss: 0.7355 - val_accuracy: 0.6087\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4543 - accuracy: 0.7839 - val_loss: 0.7349 - val_accuracy: 0.6087\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4514 - accuracy: 0.7990 - val_loss: 0.7363 - val_accuracy: 0.5652\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 66ms/step - loss: 0.4493 - accuracy: 0.7990 - val_loss: 0.7387 - val_accuracy: 0.5652\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4472 - accuracy: 0.7990 - val_loss: 0.7408 - val_accuracy: 0.5652\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4444 - accuracy: 0.7990 - val_loss: 0.7397 - val_accuracy: 0.6087\n"
     ]
    }
   ],
   "source": [
    "models = [init_model_33(), init_model_35(),init_model_36(), init_model_37(),init_model_38(), init_model_45()]\n",
    "histories = []\n",
    "recalls = []\n",
    "# callbacks = [EarlyStopping(monitor='loss', patience=3), History()]\n",
    "callbacks = [History()]\n",
    "for model in models:\n",
    "    history = model.fit(x_train, y_train, epochs=100, batch_size=128, validation_split =0.1,  callbacks=callbacks)\n",
    "    histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1294, 12)\n",
      "(None, 647, 12)\n",
      "(None, 647, 12)\n",
      "(None, 647, 12)\n",
      "(None, 323, 12)\n",
      "(None, 12)\n",
      "(None, 12)\n",
      "(None, 2)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_gaze_test = test[\"Right Gaze\"]\n",
    "left_gaze_test  = test[\"Left Gaze\"]\n",
    "right_head_test = test[\"Right HeadPose\"]\n",
    "left_head_test  = test[\"Left HeadPose\"]\n",
    "\n",
    "label_test = test['Label']\n",
    "\n",
    "right_gaze_test, left_gaze_test, right_head_test, left_head_test = parseData(right_gaze_test), parseData(left_gaze_test), parseData(right_head_test), parseData(left_head_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_head_test  = padData(left_head_test,  max_length)\n",
    "right_head_test = padData(right_head_test, max_length)\n",
    "left_gaze_test  = padData(left_gaze_test,  max_length)\n",
    "right_gaze_test = padData(right_gaze_test, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-30.842  29.423 -42.626 ... -19.488  18.949 -27.182]\n",
      "  [-27.754  35.781 -45.283 ... -12.957  19.953 -23.791]\n",
      "  [-24.957  36.39  -44.126 ... -15.066  18.399 -23.781]\n",
      "  ...\n",
      "  [-22.96   33.787 -40.85  ... -12.419  23.152 -26.273]\n",
      "  [-19.963  39.413 -44.18  ...  -7.789  25.312 -26.484]\n",
      "  [-10.705  44.444 -45.715 ...  -8.201  22.595 -24.037]]\n",
      "\n",
      " [[ 27.151  -2.31   27.249 ...  17.677   5.521  18.519]\n",
      "  [ 10.049  39.664  40.917 ...   4.425  16.695  17.271]\n",
      "  [ -3.938  40.457 -40.648 ...  -1.816  28.817 -28.874]\n",
      "  ...\n",
      "  [ 32.216   8.621  33.35  ...  46.066   0.491  46.068]\n",
      "  [ 27.958  10.575  29.891 ...  41.71    0.603  41.714]\n",
      "  [ 41.273  19.257  45.544 ...  41.396  -4.189  41.608]]\n",
      "\n",
      " [[ -8.005  83.613 -83.996 ...  -8.876  73.29  -73.826]\n",
      "  [-10.669  82.863 -83.547 ...  -7.906  68.514 -68.968]\n",
      "  [ -9.81   82.016 -82.6   ...  -4.808  70.742 -70.905]\n",
      "  ...\n",
      "  [ 28.952  59.983  66.604 ...  -8.003  76.504 -76.922]\n",
      "  [ 14.985  37.377  40.269 ...  13.966  81.658  82.844]\n",
      "  [ 27.608  66.42   71.929 ...  -5.71   79.005 -79.211]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-36.048  18.031 -40.305 ... -25.773  -9.84  -27.588]\n",
      "  [-78.323 -44.967 -90.314 ... -72.34  -47.147 -86.348]\n",
      "  [-80.724 -51.194 -95.589 ... -71.563 -52.495 -88.753]\n",
      "  ...\n",
      "  [  3.182  50.164  50.265 ... -15.864  52.233 -54.589]\n",
      "  [ 21.512  -3.407  21.78  ...  33.262 -30.176  44.91 ]\n",
      "  [ 59.308 -50.886  78.146 ...  51.188 -58.019  77.372]]\n",
      "\n",
      " [[-20.4     8.287 -22.019 ... -25.656  10.229 -27.62 ]\n",
      "  [-24.004   9.994 -26.001 ... -29.77    8.922 -31.078]\n",
      "  [-27.781  12.568 -30.492 ... -21.372   7.865 -22.773]\n",
      "  ...\n",
      "  [-67.155  37.904 -77.114 ... -68.772  22.236 -72.278]\n",
      "  [-62.102  39.537 -73.62  ... -66.958  19.628 -69.775]\n",
      "  [-65.52   44.936 -79.449 ... -67.918  28.309 -73.582]]\n",
      "\n",
      " [[-75.886  52.804 -92.45  ... -59.278  56.768 -82.076]\n",
      "  [-28.489  18.923 -34.201 ... -62.39   31.75  -70.004]\n",
      "  [-67.832  60.076 -90.611 ... -48.008  53.002 -71.512]\n",
      "  ...\n",
      "  [ 95.666  37.97  102.926 ...  76.421  16.969  78.283]\n",
      "  [ 98.496  37.782 105.494 ...  79.116  19.372  81.453]\n",
      "  [ 99.198  35.229 105.268 ...  78.935  17.407  80.831]]], shape=(48, 1294, 12), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_test = []\n",
    "\n",
    "for i in range(len(left_gaze_test)):\n",
    "    x_test.append(tf.convert_to_tensor([\n",
    "                                            np.hstack(\n",
    "                                                        (left_gaze_test[i], right_gaze_test[i], left_head_test[i], right_head_test[i])\n",
    "                                                     )\n",
    "                                            ], dtype=tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "x_test = tf.convert_to_tensor(np.vstack(x_test), dtype=tf.float32)\n",
    "\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "recalls = []\n",
    "precisions = []\n",
    "f1s = []\n",
    "for model in models:\n",
    "    predictions = model.predict(x_test)\n",
    "    recall = recall_score(label_test, np.argmax(predictions, axis=1))\n",
    "    recalls.append(recall)\n",
    "    precision = precision_score(label_test, np.argmax(predictions, axis=1))\n",
    "    precisions.append(precision)\n",
    "    f1 = f1_score(label_test, np.argmax(predictions, axis=1))\n",
    "    f1s.append(f1)\n",
    "\n",
    "# print(recalls)\n",
    "# label_predictions = []\n",
    "\n",
    "# convert from category to label\n",
    "# for prediction in predictions:\n",
    "#     if prediction[0] > prediction[1]:\n",
    "#         label_predictions.append(0)\n",
    "#     else: label_predictions.append(1)\n",
    "    \n",
    "# label_predictions = np.array(label_predictions)\n",
    "# label_test = np.array(label_test)\n",
    "\n",
    "# print(label_predictions)\n",
    "# print(label_test)\n",
    "\n",
    "# # calc acc\n",
    "# true_count = 0\n",
    "# for idx, label in enumerate(label_predictions):\n",
    "#     if label == label_test[idx]:\n",
    "#         true_count += 1\n",
    "        \n",
    "# print(\"Accuracy on test set: \", true_count/(len(label_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = ['33', '35', '36', '37', '38', '45']\n",
    "x_axis = np.arange(len(langs))\n",
    "ax.bar(x_axis-0.2,recalls, width=0.2, color='r', label= \"Recall\")\n",
    "ax.bar(x_axis,precisions, width=0.2, color = 'g', label= \"Precision\")\n",
    "ax.bar(x_axis+0.2,f1s, width=0.2, color = 'b', label= \"F1\")\n",
    "plt.xticks((x_axis), langs)\n",
    "ax.title.set_text('Recall scores of all models')\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3239.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.502007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Label\n",
       "count  3239.000000\n",
       "mean      0.502007\n",
       "std       0.500073\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       1.000000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df  = pd.read_csv('data_20s.csv')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(series):\n",
    "    final_series = []\n",
    "    for ser in series:\n",
    "        temp = []\n",
    "        for x in \"[],\":\n",
    "            ser = ser.replace(x, \"\")\n",
    "        new_ser  = np.fromstring(ser, dtype=float, sep=\" \")\n",
    "        for i in range(0, len(new_ser), 3):\n",
    "            chunk = [new_ser[i], new_ser[i + 1], new_ser[i + 2]]\n",
    "            temp.append(chunk)\n",
    "        final_series.append(temp)\n",
    "    return np.array(final_series, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "599\n",
      "598 0\n",
      "597 1\n",
      "537 2\n",
      "451 7\n",
      "298 36\n",
      "98 58\n",
      "97 188\n",
      "97 302\n",
      "80 750\n",
      "44 1976\n",
      "0 1977\n",
      "0 1978\n",
      "0 1979\n",
      "0 1980\n",
      "0 [1977, 1978, 1979, 1980]\n"
     ]
    }
   ],
   "source": [
    "max_length = 0\n",
    "for lgaze in parseData(df['Left Gaze']):\n",
    "    if len(lgaze) > max_length:\n",
    "        max_length = len(lgaze)\n",
    "        \n",
    "print(max_length)\n",
    "\n",
    "min_length = max_length\n",
    "indices = []\n",
    "for idx, lgaze in enumerate(parseData(df['Left Gaze'])):\n",
    "    if len(lgaze) <= min_length:\n",
    "        min_length = len(lgaze)\n",
    "        print(min_length, idx)\n",
    "    if len(lgaze) == 0:\n",
    "        indices.append(idx)\n",
    "\n",
    "print(min_length, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(indices)\n",
    "df = df.drop([58, 188, 302, 80, 44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-cheat:  1609\n",
      "Cheat:  1621\n",
      "(2252, 966)\n"
     ]
    }
   ],
   "source": [
    "print(\"Non-cheat: \", len(df[df['Label']==0]))\n",
    "print(\"Cheat: \", len(df[df['Label']==1]))\n",
    "\n",
    "grouped = df.groupby(df.Label)\n",
    "df1 = grouped.get_group(1)\n",
    "df2 = grouped.get_group(0)\n",
    "\n",
    "df2_1 = df2.iloc[:1609,:]\n",
    "df2_2 = df2.iloc[1609:1626,:]\n",
    "\n",
    "df1_train = df1.iloc[:1126,:]\n",
    "df2_train = df2_1.iloc[:1126,:]\n",
    "\n",
    "df1_test = df1.iloc[1126:1609,:]\n",
    "df2_test = df2_1.iloc[1126:1609,:]\n",
    "\n",
    "train = pd.concat([df1_train, df2_train])\n",
    "test  = pd.concat([df1_test, df2_test, df2_2])\n",
    "\n",
    "# shuffle the train set\n",
    "train = train.sample(frac=1)\n",
    "\n",
    "print((len(train), len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-cheat in train:  1126\n",
      "Cheat in train:  1126\n"
     ]
    }
   ],
   "source": [
    "print(\"Non-cheat in train: \", len(train[train['Label']==0]))\n",
    "print(\"Cheat in train: \", len(train[train['Label']==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def padData(series, length):\n",
    "    for idx, ser in enumerate(series):\n",
    "        times = math.floor(length / len(ser))\n",
    "        add = length % len(ser)\n",
    "        \n",
    "        temp = ser[::-1]\n",
    "        for _ in range(1, times):\n",
    "            series[idx] = np.append(series[idx], temp, axis=0)\n",
    "            temp = temp[::-1]\n",
    "        if add != 0:\n",
    "            series[idx] = np.append(series[idx], temp[0:add], axis=0)\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_gaze_train = train[\"Right Gaze\"]\n",
    "left_gaze_train  = train[\"Left Gaze\"]\n",
    "right_head_train = train[\"Right HeadPose\"]\n",
    "left_head_train  = train[\"Left HeadPose\"]\n",
    "\n",
    "label_train = train['Label']\n",
    "\n",
    "right_gaze_train, left_gaze_train, right_head_train, left_head_train = parseData(right_gaze_train), parseData(left_gaze_train), parseData(right_head_train), parseData(left_head_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_head_train  = padData(left_head_train,  max_length)\n",
    "right_head_train = padData(right_head_train, max_length)\n",
    "left_gaze_train  = padData(left_gaze_train,  max_length)\n",
    "right_gaze_train = padData(right_gaze_train, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = np.array(label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "for i in range(len(label_train)):\n",
    "    y_train.append(\n",
    "        tf.convert_to_tensor(\n",
    "            np.reshape(tf.keras.utils.to_categorical(label_train[i], num_classes=2), (1, 2))                 \n",
    "                            )\n",
    "             )\n",
    "    \n",
    "y_train = tf.convert_to_tensor(np.vstack(y_train), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-27.853  27.991  39.488 ... -47.324  31.712  56.967]\n",
      "  [-28.921  28.055  40.292 ... -48.914  31.442  58.148]\n",
      "  [-27.5    27.119  38.622 ... -48.665  30.086  57.215]\n",
      "  ...\n",
      "  [-25.189  58.553  63.742 ... -69.147  70.691  98.886]\n",
      "  [-26.093  57.239  62.906 ... -67.727  71.413  98.421]\n",
      "  [-26.093  57.239  62.906 ... -67.727  71.413  98.421]]\n",
      "\n",
      " [[-19.541  36.441  41.349 ... -30.472  17.887  35.333]\n",
      "  [-21.496  37.822  43.504 ... -30.264  21.347  37.035]\n",
      "  [-19.52   36.588  41.469 ... -27.84   19.561  34.025]\n",
      "  ...\n",
      "  [-15.336  48.173  50.555 ... -25.339  25.622  36.035]\n",
      "  [-18.128  53.063  56.074 ... -21.162  34.849  40.771]\n",
      "  [-19.083  52.702  56.05  ... -22.54   34.221  40.978]]\n",
      "\n",
      " [[-22.094  85.045  87.868 ... -12.05   54.932  56.238]\n",
      "  [-21.055  87.359  89.86  ... -14.815  59.382  61.202]\n",
      "  [-20.165  87.755  90.042 ... -15.641  61.025  62.997]\n",
      "  ...\n",
      "  [ 20.334  -5.793  21.143 ...  38.354  84.927  93.186]\n",
      "  [ 20.334  -5.793  21.143 ...  38.354  84.927  93.186]\n",
      "  [ 19.27   -4.908  19.885 ...  36.832  86.564  94.074]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-26.624  14.961  30.539 ... -43.224   8.7    44.091]\n",
      "  [-23.593  29.573  37.832 ... -12.549  -3.03   12.91 ]\n",
      "  [-13.714  42.023  44.204 ...  -0.285  -1.861   1.883]\n",
      "  ...\n",
      "  [124.471  90.112 153.666 ... 118.305  22.538 120.433]\n",
      "  [121.234  42.427 128.444 ...  92.453  15.406  93.728]\n",
      "  [121.234  42.427 128.444 ...  92.453  15.406  93.728]]\n",
      "\n",
      " [[-20.891  31.168  37.522 ... -37.451  18.072  41.583]\n",
      "  [-21.756  31.435  38.23  ... -37.138  18.781  41.616]\n",
      "  [-21.159  31.39   37.855 ... -36.558  19.009  41.204]\n",
      "  ...\n",
      "  [ 29.856  17.37   34.542 ...  22.266  12.991  25.778]\n",
      "  [ 31.256  16.461  35.325 ...  23.969  14.15   27.834]\n",
      "  [ 31.256  16.461  35.325 ...  23.969  14.15   27.834]]\n",
      "\n",
      " [[ -4.027  79.262  79.365 ... -23.105  81.041  84.27 ]\n",
      "  [-25.516  94.69   98.067 ... -17.751  83.342  85.211]\n",
      "  [ -5.735  76.466  76.68  ... -29.773  73.284  79.101]\n",
      "  ...\n",
      "  [ 36.982  42.715  56.5   ...   6.232  42.574  43.028]\n",
      "  [ 36.982  42.715  56.5   ...   6.232  42.574  43.028]\n",
      "  [ 41.313  28.078  49.951 ...  15.568  21.226  26.323]]], shape=(2252, 599, 12), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]], shape=(2252, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_train = []\n",
    "\n",
    "for i in range(len(left_gaze_train)):\n",
    "    x_train.append(tf.convert_to_tensor([\n",
    "                                            np.hstack(\n",
    "                                                        (left_gaze_train[i], right_gaze_train[i], left_head_train[i], right_head_train[i])\n",
    "                                                     )\n",
    "                                            ], dtype=tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "x_train = tf.convert_to_tensor(np.vstack(x_train), dtype=tf.float32)\n",
    "\n",
    "print(x_train)\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_gaze_test = test[\"Right Gaze\"]\n",
    "left_gaze_test  = test[\"Left Gaze\"]\n",
    "right_head_test = test[\"Right HeadPose\"]\n",
    "left_head_test  = test[\"Left HeadPose\"]\n",
    "\n",
    "label_test = test['Label']\n",
    "\n",
    "right_gaze_test, left_gaze_test, right_head_test, left_head_test = parseData(right_gaze_test), parseData(left_gaze_test), parseData(right_head_test), parseData(left_head_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_head_test  = padData(left_head_test,  max_length)\n",
    "right_head_test = padData(right_head_test, max_length)\n",
    "left_gaze_test  = padData(left_gaze_test,  max_length)\n",
    "right_gaze_test = padData(right_gaze_test, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 45.679  22.428  50.888 ...  33.667  25.695  42.352]\n",
      "  [ 43.788  21.278  48.684 ...  32.631  25.063  41.145]\n",
      "  [ 46.069  18.498  49.644 ...  33.921  23.145  41.065]\n",
      "  ...\n",
      "  [-17.37   40.155  43.751 ... -34.259  44.602  56.241]\n",
      "  [-17.01   40.044  43.507 ... -33.2    45.901  56.649]\n",
      "  [-17.01   40.044  43.507 ... -33.2    45.901  56.649]]\n",
      "\n",
      " [[ -0.78   47.38   47.386 ... -14.949  46.261  48.616]\n",
      "  [ -0.814  49.463  49.47  ... -14.005  47.321  49.35 ]\n",
      "  [ -2.568  49.585  49.651 ... -15.153  47.398  49.761]\n",
      "  ...\n",
      "  [-14.199  42.451  44.763 ... -30.818  44.764  54.347]\n",
      "  [-13.25   41.417  43.485 ... -28.174  44.116  52.345]\n",
      "  [-13.25   41.417  43.485 ... -28.174  44.116  52.345]]\n",
      "\n",
      " [[-12.117  40.077  41.869 ... -27.04   44.452  52.03 ]\n",
      "  [ -8.297  42.745  43.543 ... -22.644  46.491  51.712]\n",
      "  [-10.743  41.512  42.88  ... -25.538  46.89   53.393]\n",
      "  ...\n",
      "  [-11.666  42.979  44.534 ... -32.526  49.787  59.47 ]\n",
      "  [ -9.657  43.32   44.383 ... -29.719  50.7    58.768]\n",
      "  [ -9.657  43.32   44.383 ... -29.719  50.7    58.768]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  5.64   42.048  42.424 ...   6.36   27.342  28.072]\n",
      "  [ 12.415  43.494  45.231 ...   9.971  26.127  27.965]\n",
      "  [ 12.163  47.237  48.778 ...   8.044  27.066  28.236]\n",
      "  ...\n",
      "  [ 43.607  71.567  83.806 ...  40.442  43.53   59.417]\n",
      "  [ 43.607  71.567  83.806 ...  40.442  43.53   59.417]\n",
      "  [ 42.32   72.961  84.346 ...  38.568  43.224  57.929]]\n",
      "\n",
      " [[-11.595  46.854  48.268 ... -24.547  46.995  53.02 ]\n",
      "  [-10.395  48.643  49.742 ... -23.516  47.572  53.067]\n",
      "  [ -8.951  49.322  50.127 ... -22.758  47.605  52.765]\n",
      "  ...\n",
      "  [  5.852  68.06   68.311 ... -12.985  72.872  74.02 ]\n",
      "  [  5.852  68.06   68.311 ... -12.985  72.872  74.02 ]\n",
      "  [  5.116  71.191  71.374 ... -12.416  75.472  76.487]]\n",
      "\n",
      " [[ 60.702 -14.753  62.469 ...  53.378 -30.299  61.378]\n",
      "  [ 18.658  53.039  56.225 ...   9.913  28.27   29.957]\n",
      "  [ -3.216  65.294  65.373 ...  -5.639  50.559  50.873]\n",
      "  ...\n",
      "  [-61.176  27.458  67.056 ... -40.166  19.34   44.579]\n",
      "  [-57.256  29.377  64.352 ... -35.994  19.672  41.019]\n",
      "  [-57.256  29.377  64.352 ... -35.994  19.672  41.019]]], shape=(966, 599, 12), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x_test = []\n",
    "\n",
    "for i in range(len(left_gaze_test)):\n",
    "    x_test.append(tf.convert_to_tensor([\n",
    "                                            np.hstack(\n",
    "                                                        (left_gaze_test[i], right_gaze_test[i], left_head_test[i], right_head_test[i])\n",
    "                                                     )\n",
    "                                            ], dtype=tf.float32))\n",
    "\n",
    "\n",
    "\n",
    "x_test = tf.convert_to_tensor(np.vstack(x_test), dtype=tf.float32)\n",
    "\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_48\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_138 (Conv1D)          (None, 599, 12)           444       \n",
      "_________________________________________________________________\n",
      "average_pooling1d_125 (Avera (None, 299, 12)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 299, 12)           444       \n",
      "_________________________________________________________________\n",
      "lstm_48 (LSTM)               (None, 12)                1200      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "flatten_48 (Flatten)         (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 2)                 26        \n",
      "=================================================================\n",
      "Total params: 2,114\n",
      "Trainable params: 2,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 3s 62ms/step - loss: 0.7174 - accuracy: 0.5257 - val_loss: 0.6853 - val_accuracy: 0.5531\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6736 - accuracy: 0.5844 - val_loss: 0.6548 - val_accuracy: 0.5796\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6584 - accuracy: 0.5943 - val_loss: 0.6355 - val_accuracy: 0.6018\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6372 - accuracy: 0.6422 - val_loss: 0.5978 - val_accuracy: 0.7345\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.6188 - accuracy: 0.6703 - val_loss: 0.5786 - val_accuracy: 0.7522\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.6004 - accuracy: 0.6885 - val_loss: 0.5561 - val_accuracy: 0.7345\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.6115 - accuracy: 0.6831 - val_loss: 0.5467 - val_accuracy: 0.7434\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5981 - accuracy: 0.6915 - val_loss: 0.5425 - val_accuracy: 0.7389\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.5921 - accuracy: 0.6964 - val_loss: 0.5327 - val_accuracy: 0.7876\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5717 - accuracy: 0.7137 - val_loss: 0.5352 - val_accuracy: 0.7655\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.5589 - accuracy: 0.7236 - val_loss: 0.5240 - val_accuracy: 0.7965\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.5620 - accuracy: 0.7201 - val_loss: 0.5480 - val_accuracy: 0.7611\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5845 - accuracy: 0.6807 - val_loss: 0.5475 - val_accuracy: 0.7345\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5802 - accuracy: 0.7098 - val_loss: 0.5172 - val_accuracy: 0.7788\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5557 - accuracy: 0.7335 - val_loss: 0.5341 - val_accuracy: 0.7345\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.5580 - accuracy: 0.7241 - val_loss: 0.5470 - val_accuracy: 0.7168\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5630 - accuracy: 0.7389 - val_loss: 0.5004 - val_accuracy: 0.7832\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5401 - accuracy: 0.7409 - val_loss: 0.5030 - val_accuracy: 0.7832\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5373 - accuracy: 0.7453 - val_loss: 0.5161 - val_accuracy: 0.7655\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.5485 - accuracy: 0.7270 - val_loss: 0.5484 - val_accuracy: 0.7478\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.5442 - accuracy: 0.7241 - val_loss: 0.5485 - val_accuracy: 0.7035\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5363 - accuracy: 0.7275 - val_loss: 0.5614 - val_accuracy: 0.7080\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.5408 - accuracy: 0.7330 - val_loss: 0.5200 - val_accuracy: 0.7566\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5245 - accuracy: 0.7488 - val_loss: 0.5248 - val_accuracy: 0.7566\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.5212 - accuracy: 0.7527 - val_loss: 0.5218 - val_accuracy: 0.7478\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5329 - accuracy: 0.7473 - val_loss: 0.5512 - val_accuracy: 0.7434\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5538 - accuracy: 0.7345 - val_loss: 0.5359 - val_accuracy: 0.7522\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5174 - accuracy: 0.7468 - val_loss: 0.5196 - val_accuracy: 0.7522\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5089 - accuracy: 0.7473 - val_loss: 0.5358 - val_accuracy: 0.7566\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.5124 - accuracy: 0.7532 - val_loss: 0.5093 - val_accuracy: 0.7655\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.5198 - accuracy: 0.7483 - val_loss: 0.5098 - val_accuracy: 0.7876\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.5080 - accuracy: 0.7626 - val_loss: 0.4985 - val_accuracy: 0.7655\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4942 - accuracy: 0.7695 - val_loss: 0.4882 - val_accuracy: 0.7876\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4705 - accuracy: 0.7843 - val_loss: 0.4873 - val_accuracy: 0.7920\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4659 - accuracy: 0.7833 - val_loss: 0.5056 - val_accuracy: 0.7965\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4795 - accuracy: 0.7754 - val_loss: 0.4824 - val_accuracy: 0.7965\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4930 - accuracy: 0.7591 - val_loss: 0.4922 - val_accuracy: 0.7788\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4676 - accuracy: 0.7863 - val_loss: 0.5398 - val_accuracy: 0.7566\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4772 - accuracy: 0.7873 - val_loss: 0.4940 - val_accuracy: 0.7655\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4769 - accuracy: 0.7848 - val_loss: 0.4796 - val_accuracy: 0.7788\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.4593 - accuracy: 0.8016 - val_loss: 0.4686 - val_accuracy: 0.8186\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4343 - accuracy: 0.8119 - val_loss: 0.4855 - val_accuracy: 0.8142\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4687 - accuracy: 0.7902 - val_loss: 0.4868 - val_accuracy: 0.7832\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4604 - accuracy: 0.8006 - val_loss: 0.4887 - val_accuracy: 0.7743\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.4549 - accuracy: 0.7863 - val_loss: 0.4981 - val_accuracy: 0.7566\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4414 - accuracy: 0.8011 - val_loss: 0.4833 - val_accuracy: 0.7743\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.4269 - accuracy: 0.8174 - val_loss: 0.4778 - val_accuracy: 0.8186\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4309 - accuracy: 0.8055 - val_loss: 0.4649 - val_accuracy: 0.7965\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4346 - accuracy: 0.8115 - val_loss: 0.4991 - val_accuracy: 0.7920\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4227 - accuracy: 0.8164 - val_loss: 0.4542 - val_accuracy: 0.7876\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4182 - accuracy: 0.8105 - val_loss: 0.4640 - val_accuracy: 0.7699\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4254 - accuracy: 0.8159 - val_loss: 0.4698 - val_accuracy: 0.7920\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.4322 - accuracy: 0.8144 - val_loss: 0.4900 - val_accuracy: 0.7699\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.4392 - accuracy: 0.8070 - val_loss: 0.4277 - val_accuracy: 0.8097\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.4222 - accuracy: 0.8189 - val_loss: 0.4637 - val_accuracy: 0.7876\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4256 - accuracy: 0.8036 - val_loss: 0.5144 - val_accuracy: 0.7434\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.4280 - accuracy: 0.8045 - val_loss: 0.5082 - val_accuracy: 0.7876\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4243 - accuracy: 0.8189 - val_loss: 0.4740 - val_accuracy: 0.7788\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.4291 - accuracy: 0.8149 - val_loss: 0.4682 - val_accuracy: 0.8009\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.4331 - accuracy: 0.8110 - val_loss: 0.5764 - val_accuracy: 0.7832\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.4430 - accuracy: 0.7966 - val_loss: 0.4884 - val_accuracy: 0.7920\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4145 - accuracy: 0.8243 - val_loss: 0.4710 - val_accuracy: 0.7743\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.3947 - accuracy: 0.8248 - val_loss: 0.4441 - val_accuracy: 0.8274\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.3926 - accuracy: 0.8282 - val_loss: 0.4733 - val_accuracy: 0.7920\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4006 - accuracy: 0.8253 - val_loss: 0.4546 - val_accuracy: 0.8097\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3886 - accuracy: 0.8337 - val_loss: 0.4584 - val_accuracy: 0.8097\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.3955 - accuracy: 0.8268 - val_loss: 0.4509 - val_accuracy: 0.7788\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.4069 - accuracy: 0.8253 - val_loss: 0.4389 - val_accuracy: 0.8053\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.3901 - accuracy: 0.8302 - val_loss: 0.4573 - val_accuracy: 0.8142\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.3895 - accuracy: 0.8277 - val_loss: 0.4729 - val_accuracy: 0.7611\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3888 - accuracy: 0.8248 - val_loss: 0.4470 - val_accuracy: 0.8230\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.3731 - accuracy: 0.8430 - val_loss: 0.4628 - val_accuracy: 0.8142\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3837 - accuracy: 0.8337 - val_loss: 0.4600 - val_accuracy: 0.7832\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3702 - accuracy: 0.8421 - val_loss: 0.4486 - val_accuracy: 0.8053\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3655 - accuracy: 0.8455 - val_loss: 0.4542 - val_accuracy: 0.8097\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3493 - accuracy: 0.8544 - val_loss: 0.4474 - val_accuracy: 0.8142\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3565 - accuracy: 0.8485 - val_loss: 0.4586 - val_accuracy: 0.8097\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3617 - accuracy: 0.8504 - val_loss: 0.4439 - val_accuracy: 0.8186\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3800 - accuracy: 0.8465 - val_loss: 0.4543 - val_accuracy: 0.8142\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3649 - accuracy: 0.8421 - val_loss: 0.4651 - val_accuracy: 0.7965\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.3700 - accuracy: 0.8421 - val_loss: 0.4610 - val_accuracy: 0.8319\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3852 - accuracy: 0.8337 - val_loss: 0.4900 - val_accuracy: 0.7832\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3762 - accuracy: 0.8440 - val_loss: 0.4376 - val_accuracy: 0.8186\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3737 - accuracy: 0.8421 - val_loss: 0.4729 - val_accuracy: 0.7965\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3685 - accuracy: 0.8381 - val_loss: 0.4485 - val_accuracy: 0.8274\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3485 - accuracy: 0.8519 - val_loss: 0.4345 - val_accuracy: 0.8363\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3797 - accuracy: 0.8332 - val_loss: 0.5056 - val_accuracy: 0.7965\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.3780 - accuracy: 0.8411 - val_loss: 0.4426 - val_accuracy: 0.8319\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.3572 - accuracy: 0.8490 - val_loss: 0.4709 - val_accuracy: 0.8451\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3662 - accuracy: 0.8406 - val_loss: 0.4475 - val_accuracy: 0.8186\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.3652 - accuracy: 0.8371 - val_loss: 0.4692 - val_accuracy: 0.7832\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.3630 - accuracy: 0.8465 - val_loss: 0.4841 - val_accuracy: 0.7920\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.3413 - accuracy: 0.8495 - val_loss: 0.4377 - val_accuracy: 0.8363\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 22ms/step - loss: 0.3295 - accuracy: 0.8539 - val_loss: 0.4410 - val_accuracy: 0.8142\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 18ms/step - loss: 0.3251 - accuracy: 0.8588 - val_loss: 0.4806 - val_accuracy: 0.8142\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3678 - accuracy: 0.8411 - val_loss: 0.4399 - val_accuracy: 0.8009\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 19ms/step - loss: 0.3381 - accuracy: 0.8554 - val_loss: 0.4503 - val_accuracy: 0.8230\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 21ms/step - loss: 0.3238 - accuracy: 0.8583 - val_loss: 0.4547 - val_accuracy: 0.8274\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.3382 - accuracy: 0.8519 - val_loss: 0.4491 - val_accuracy: 0.8230\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 20ms/step - loss: 0.3385 - accuracy: 0.8583 - val_loss: 0.4534 - val_accuracy: 0.7965\n"
     ]
    }
   ],
   "source": [
    "model_46 = init_model_46()\n",
    "history = model_46.fit(x_train, y_train, epochs=100, batch_size=128, validation_split =0.1,  callbacks=callbacks)\n",
    "histories.append(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5416666666666666, 0.7083333333333334, 0.5416666666666666, 0.4583333333333333, 0.5833333333333334, 0.625, 0.7929606625258799]\n"
     ]
    }
   ],
   "source": [
    "predictions = model_46.predict(x_test)\n",
    "recall = recall_score(label_test, np.argmax(predictions, axis=1))\n",
    "recalls.append(recall)\n",
    "precision = precision_score(label_test, np.argmax(predictions, axis=1))\n",
    "precisions.append(precision)\n",
    "f1 = f1_score(label_test, np.argmax(predictions, axis=1))\n",
    "f1s.append(f1)\n",
    "print(recalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = ['33', '35', '36', '37', '38', '45', '46']\n",
    "x_axis = np.arange(len(langs))\n",
    "ax.bar(x_axis-0.2,recalls, width=0.2, color='r', label= \"Recall\")\n",
    "ax.bar(x_axis,precisions, width=0.2, color = 'g', label= \"Precision\")\n",
    "ax.bar(x_axis+0.2,f1s, width=0.2, color = 'b', label= \"F1\")\n",
    "plt.xticks((x_axis), langs)\n",
    "ax.title.set_text('Scores of all models')\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('Recall')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot the loss and acc from training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABV1UlEQVR4nO29eZgcV3mo/35Vvcyufd8lr5JlSbYsW2YzNnh3uCEJ2LkESAgEYgKY1WQhNyS5sc3qNeAQQvix+BIIAS9gg/EueZEtybJkSdbu0TpaZ+/1/P6o6u7qnu6ZnpmurlOe8z7PPNNdVV39TU3V+c75VlFKYTAYDIaxixW0AAaDwWAIFqMIDAaDYYxjFIHBYDCMcYwiMBgMhjGOUQQGg8EwxjGKwGAwGMY4RhEYxgQiMl9ElIhEqjj2gyLydD3kMhh0wCgCg3aIyB4RSYrI5JLtG9zBfH5AonllaRaRbhF5KGhZDIbRYhSBQVd2Azfk3ojIUqAxOHEG8IdAArhcRGbU84urWdUYDMPBKAKDrvx/wPs97z8AfN97gIiME5Hvi0iHiOwVkb8VEcvdZ4vIV0XkqIjsAq4p89l/F5GDIrJfRP5JROxhyPcB4FvAy8D/Ljn3m0VkjYicFJHXReSD7vZGEfmaK+spEXna3XaJiLSXnGOPiLzDff1/ROSnIvIDEekEPigiq0RkrfsdB0XkLhGJeT6/RER+IyLHReSwiPy1iEwXkV4RmeQ57nz3+kWH8bcb3mAYRWDQlWeBNhE52x2g3wv8oOSYO4FxwELgbTiK40/dfR8GrgVWACtxZvBe/hNIA6e5x1wO/Hk1gonIXOAS4Ifuz/tL9v3KlW0KsBzY4O7+KnA+cDEwEfg8kK3mO4F3AT8FxrvfmQFuAiYDq4HLgL90ZWgFfgv8Gpjp/o2PKqUOAY8D7/Gc933AfUqpVJVyGN6IKKXMj/nR6gfYA7wD+FvgX4Argd8AEUAB8wEbxzSz2PO5vwAed1//DvioZ9/l7mcjwDT3s42e/TcAj7mvPwg8PYh8fwtscF/PxBmUV7jvvwj8vMxnLKAPWFZm3yVAe7lr4L7+P8CTQ1yzT+W+1/1b1lc47r3AM+5rGzgErAr6f25+gv0xtkaDzvx/wJPAAkrMQjgz4Riw17NtLzDLfT0TeL1kX455QBQ4KCK5bVbJ8YPxfuDfAJRSB0TkCRxT0XpgDrCzzGcmAw0V9lVDkWwicgbwdZzVThOOgnvR3V1JBoBfAN8SkYXAGcAppdTzI5TJ8AbBmIYM2qKU2ovjNL4a+O+S3UeBFM6gnmMusN99fRBnQPTuy/E6zopgslJqvPvTppRaMpRMInIxcDrwRRE5JCKHgAuBG1wn7uvAojIfPQr0V9jXgzOY577DxjEreSktE/yvwFbgdKVUG/DXQE6rVZIBpVQ/8BMcv8af4ChbwxjHKAKD7nwIuFQp1ePdqJTK4Axo/ywirSIyD/g0BT/CT4BPiMhsEZkA3Oz57EHgEeBrItImIpaILBKRt1UhzwdwzFSLcez/y4FzcAbyq3Ds9+8QkfeISEREJonIcqVUFvgu8HURmek6s1eLSBzYDjSIyDWu0/ZvgfgQcrQCnUC3iJwFfMyz7wFguoh8SkTi7vW50LP/+zjmr99joN/FMAYxisCgNUqpnUqpdRV2/xXObHoX8DTwI5zBFhzTzcPARuAlBq4o3o9jWtoCnMBxxA4aBioiDTiO1juVUoc8P7txZtYfUErtw1nBfAY4juMoXuae4rPAJuAFd9+tgKWUOoXj6P0OzoqmByiKIirDZ4E/Brrcv/X/5XYopbqAdwLX4fgAXgPe7tn/DI6T+iWl1J4hvscwBhClTGMag2GsISK/A36klPpO0LIYgscoAoNhjCEiF+CYt+a4qwfDGMc305CIfFdEjojIKxX2i4jcISI7RORlETnPL1kMBoODiPwnTo7Bp4wSMOTwbUUgIm8FuoHvK6XOKbP/ahwb79U4URe3K6UuLD3OYDAYDP7i24pAKfUkjkOsEu/CURJKKfUsML7eNVsMBoPBQKAJZbMoTpJpd7cdLD1QRD4CfASgubn5/LPOOqsuAhoMBsMbhRdffPGoUqo0PwUIVhFImW1l7VRKqXuBewFWrlyp1q2rFE1oMBgMhnKIyN5K+4LMI2inOPNzNnAgIFkMBoNhzBKkIvgl8H43euginJonA8xCBoPBYPAX30xDIvJjnKqKk91a63+PU+gLpdS3gIdwIoZ2AL0UygcbDAaDoY74pgiUUjcMsV8BN/r1/QaDwWCoDlNryGAwGMY4RhEYDAbDGMcoAoPBYBjjGEVgMGjEmvv+i/s/fSsA9990Cw/+1W0BS2QYCxhFYDBoROtzEVbELualXz3MivibWNa8mq1rnw1aLMMbHNOz2GDQgAe//HUaDzVwRttSAMb9znJaywP7fvAsZ62+KEDpDG90jCIwGDRg+rEZTGubnX8ftxvyrxe3nh+ESIYxhFEEBkNAvPb8C7z+n88hymZR6+IB+7fN3sqZ7cEUWHzo419BiULFFC394wBQKM74xGXMOvOMAcc/8MXbkMYI13zp0/UW1VADjCIwGAJi2w9/x/LWi/PvTySO0hRpJplN0Jk8wQU3vJvOr2ypu1ybHn2Mc1scU1Qqm8BqiWCLY6fafPuvmHXPQEWwXK126gMYQolRBIZR89CXv0GmK8l1X/lC0KKEimgqBo3QlTpBa3QCBxJ7uOIbNxUds7FrGzOa5lQ4Q23p7+nhic/dSyqSZEKTo6CiVpxNXc+xtNXpGWUNEV/y0Me/wpRLz+CCd7/Ld3kNtcNEDRlGzbm9K1lhXzz0gYYiGqSJVDbB7sQ2etPdpKcPrMKupH49xX97yz0saVvJclcJ9KQ76Ul30nTeVDZ3vQBARKIDPrfzxRfzr89tuYjYk6n6CGyoGWZFYDAEwLEDB1nUupjO5HGuvutzAJzBVYHKpFIFpXMi0cHSb7wbgDMBPgRbPvNLTmtdwskjHYyfWuhvsu0/fpc3JQHYlhlWwoZZERgMAbD2ju8DcCp1cvAD67cgQPoKX3YguWfA/r50DwBrv/Ojou1T7VlF79NZsyIIG0Z1Gwx15IFP3cq07GyWNKwEC6Z+8JygRcpjpx2H8OE3dXLFdQOjfw6N28+05Gwynf35bQ9/5W6WNJ7Lgd69zGyaBxhFEEbMisBgqCPLGy5mRtNcolaMfd07WHT+UDkCCinb1bX2RFQMgPnnn1d2f8NUJ4yUvsK2MzvOBiCj0vltac9rQzgwisBgqBPJRKLo/cV3Dd2LqV6Woce+/V3ObltBKptk0swZZY+ZsGguUFg5AEQsx3kctwoJcGllVgRhwygCg6FO7N34ctAiVGTG9qmAkzRWidNWrQQgquIAdOzbl993eMaR/GujCMKH8REYhs0Df30bEzqnELt0Imdf9vagxQkF/T09HP/BVmY1zQ9alDy/+pc7GLe/jb5sN2e2LXM2qsqKoG3SJI5m+olKjPtvuoX5nMGE+BQ29qzlmls+T/vNTwHFZiJDODArAsOwmdU7n3ktp3HksW0c2bUraHFCwRP3fC+vBE4mj7I+8cwwPu2Pj6CpPc7clkUFJVAFyWyCqMSZrRYyIe6EkKpmZ9/61BoAMmIUQdgwisBQkdeef4EnbryXvZs2FW2PWY5pIJKNcHzf60GIFjoyfcn86wOzD3LdN26u8pN+egkGKpihvi2ZTRCzYsSsWH5bwwzHiXz+x/6glsIZ6ohRBIaK7P3esyxqPZut//rbou05B2FExTn84rYgRAsdmZ6CIpgwf9YgRw7Er5ihXP2gHMlMP1tbN1U42j0mmyRmx4lZcY4njtDes5uVN7zbJwkN9cL4CAwD+O3t3ya6XTirbTkAFoUBo7+nh0a7CYCoFWNa9yyIQSLTV+5UBhfpA5zLxvyVKwKVJYdXEWzoW8O1t3+Bhbxz0M8kswlaIq3E7AZe79vNpXf/ZX6fZdtkfZPW4CdGERgGMO/1eTS2NuffexXBrvUbaHMHkCa7mfGxSQAksv0YKmNnCo/alLlzA5SkgC2OTEf6DzBx9cKqPpPKJmiKtGCJTZpk+YPqmA1tqA1GERjyHNixg13ffIL5LcVlhuc0LeSlT97H0fQhmlZPpw3HtNEWnZA/pj4pT+HkkRu/ydLWVSM/gfhzdW2xOZY4zHnffG/Vn0mpJJY7EUhLcZiobds4bmJzN4QN4yMw5Hnpjv8eoAQAetPdtMUmMLfhNHqPHAcgk03TFGnJ7zdUxtth7BW3ime1DBbXP1ossclkM8P6TMIumACblk0tPl9kYGVSQzgwisAAQPepTpY2XDBg+95lB1n+zT/iUF87llikTjkDweH+/flj+jI9mFngQO7/3K08duO/Fm278u7hd/Cq5ZXt2LePZz7+7zz5Hz/AFpssw1MEjYsdU2B/ppdLPvyBsseYOyF8GEVgAOCpe75XtnzwvGVLAMiSxRKbbK+z+D+WOZQ/pi9tWlOVY4V9Mae36lNUDuDZO37MvJYzaFjv+Agy2eHF/L/5z97Hzq4tbB+3dcA+O2IszWHF/OfGMPf/9W20nmrlkrs/htqfgJaBx0xddBoASmWxsDg9uwRssBc2QodzTNbEigygtK7Q6KjdHNtKAhHylUJPJY8P6/OxeJy33f0XQxxl1gRhwyiCMcyK7GpodV6PY1LRvg39a4gl48yOvwWALBkssWmJOslD4+fN4pVdL5BqSDGJaZiHv5hnvvdDTuf0/PsDvXvpmHSE2bxlmGeqrY/AyhTnDmSGaRoa9Ny2MTCEFaMIDHQeO8aE+OSibdd+s7j/cFapfCIZwKQFc1j1h/8LgDUf/57fIoaO3leOQnNBEaRWx7jmhuH7BwYp/TNskokEZzUX5zBkVQ0VgXEWhxajwg288pvf0RadwOG+do70HWBD75oBx3idiqeSx5hzTrHt26wHiolnGove53wtI6FW/Qi6jh0n6ikNAdBPT03ObQg3vq4IRORK4HbABr6jlLqlZP8E4LvAIqAf+DOl1Ct+ymSAZ3/yMxrWZJncMB2A42t2M7dpOgdbXufaf/485dqSKCn4AfZO3MuSeNy711+BQ0hUYm5dHuc65Xwtw6aGGrZj794BbqBka+0KxEUi9tAHGbTEtxWBiNjA3cBVwGLgBhFZXHLYXwMblFLnAu/HURoGn0k8cTSvBACaMs7wMOdtlUsfeB3CF/7Ze4r2GTUwkKjESWYK2daxIsUZDN1HOorep7JJ3va5D9X8e+rVUc1QO/w0Da0CdiildimlksB9wLtKjlkMPAqglNoKzBeRaT7KZChDs91KJpvm7Le9teIxylUER/r2V+hgZR5+gK1rn2X7Z3/F3JZFNVKQtVOzPUdPFL3f0reOtkmTKhw9fCwTPhpa/FQEswBvjeJ2d5uXjcC7AURkFTAPmF16IhH5iIisE5F1HR0dpbsNw6Z40G6OtNKb6Rl01qrEGZCyyoSKDsZrP308n3HdGh3HerWGDcPqPeAfyc5if4CK1HYtp8OqxzAy/FTh5aaIpXfeLcDtIrIB2ASsBwYYLZVS9wL3AqxcudJYIkbBg391G8taVxdta4m0cSJ5dNDP5XwElXIGfCqHEz5U8YW47tYvVDiwytNRO1NLqtsxVXWlTtAanQAZ808zOPipCNqBOZ73s4ED3gOUUp3AnwKIiAC73R+DTyxrXj1gW8SK0pU+NejnlLt2VGXjGY1uzmEnLYjBsf7D7J/4+gjyBkqo4aXNJpzIrx28SmNnEys/954hPmEYK/ipCF4ATheRBcB+4Hrgj70HiMh4oNf1Ifw58KSrHAx1pktODH0Q4cwiXveL+2l9yuL1ufvp33GCqcxi1R3v8+W7IsqJpR//oTNZtvQPa3PSGk3cVSIDNljjorzja39Vm5OWwTiLw4dvPgKlVBr4OPAw8CrwE6XUZhH5qIh81D3sbGCziGzFiS76pF/yGAbHmjG4fVeyzsOtKvoI9H34jz3yGs2RNqLbYHnTxcxsmsdLv3rYl++KECOj0sw4Y2AV18BJO8uLSKN/tvzyK0aD7vjq5ldKPQQ8VLLtW57Xa8GTh28IjKlLB49zF9f2XX5FoOfD/9SN32Fa4yyWtDpVVRe1np3ft/+3Gzjvqitq+n0nj3RwRutS+jO9NXacjl7JPnHjvaxofRMAsbbGIY4eOX6WzTb4h8ksHmNUqja55NJLBv1cThFUmvHpuB5Y0HpmPoKnFEnVXuLNjz4GwPFELSPbajOwepVg44RxNTlnZXS8GwyDYQJ/NSKZSPDqF+6nLTaBw337uejO99f0/M9/4gf5qpOlNDQ3l92eI2s5K4GkGtiSMpxzwNpJ/cS/f5/pr07iRHoX8xpmcNhur9m5ofbDauuU2uUOGN4YmBWBRqz5/n1MaphGRqWZ2TSXAzt21PT8uWxiby2hzZ3rWJ8aOs79bf/0UTZ1Pc+5N/9ehSP0nQW+0jmwK5io2smbeamT5kgb860znXO31LDUgjgBpLXiWP9hlrz9kpqdrxwi4ZwajGWMItCI7k1Os5fdPduwxGb9D39Zs3MnEwkiEmVb58tce0chtv2Ke27iuq/dPOTnW8a1cdXdn9Gm8bqX9Z/6CY/+5V0DtmeyaV7r2sQZH740v+31np3uq9oNVnFpAqAtOtF5P7G8OWokqBoorEf/8u7869eltpOLgRglEEaMaUgj2jITSGUTJCcnIQnZ3tTQH6qSjj17scQi4zYcX2+tJT6pefRx7kCQD39/Tw9TGmYwpaG47EX3qU5sK0JGZWidNJEEXUBtyy7naLAd56slzrxqwsIByfGBcmbbuQD0pXt4xz/5Fzaap4arLUN9MCsCDdj06GO03/wUC1vP5kTiKOQafNQoZP+JG+8l8e/7AEi7iuC6//t5Lv/MjbX5AoIzDG1+7Mn86/s/VShue3jHawBkSNPqqaeTyYe/1k7i0tLO81Ysq9m5a6lkX+/bMaQvaLQ40hpFEDaMItCAvb95Pv96f+O+mj9Hi1rPzpdDzjl9a0mQxoAjm17Lv25KtuZfn2h3ktgzVrpo8Btus/ZqiHoa9nSnOmtuPqtVgpZNbOiDRo0xDYURowgC5oFP3cJyLs6/v+6Wz/uamal8GwvqNwu8/zO30n7zU7Tf/BSZI7357RFxLJ2bH3uc6WvHAwMVnx9F86JWPH/ezlR1GdpBkFK17KNseCNhFEHANKcKMd3r1cDOYLVGGn34l9c2sGVI5mcLOYjjUpPJqgz9mV4i4szMdz3wbEE0u3iGWusVQTKRIGrF2NO9nc2d6+hbVntFI6Oo6Nd9qpPedDdZlWHZzaVV4H3ALAhCiXEWB0yD1ZR/fcWXP+W8yD33PjxUsQn+2ojrQ2FgnNk4l1PJ41hi5XsqN/Y1g2utkXix4suKowhqFT7asWcvtkTop4cr7rmpJuf0MtpM3T3/8CjjY5PZ3bWNt8y9pDZCDYVxEdSMrWufpff/7aUzdYLZTQvYltjANXeMrqJtOcyKICCSiQRbnn6GJruZ7tQpNkSeK5QlEP/+LZfcWPuOVFDfQmMRqzB/iduNdKe7SGVTRN0VQVSc67ip6zlWf+JPij5ba9PQgc2vAgUnvE4cO3CQ8bHJADRF6jMBUCijB4ZBMpHg2IGDFffv/sHTTG2YyWmtS2iwm4hm/KkTZVYEAfHMp/+d01uXQsM09nbv4NqvfTa/r1Z6YNtnH6I5UnCgbu/cxOx4LcJFi1F1SiB6/qf/w8x1k2iNjudQ3+tMb3SqnPdnexkfm0hrdDz3f+5WJsoUetKdXHX3ZwecI2vV1jQ043kndyAbqb0T2ksykRhW/aLffONfOfvwOYXPZ41/QEce/fSdLG29kE3v3MrSy94OwP5t25kyfx6xeJwWxhcdn2j05/9oVgQBMTU+i5PJo7zS+QLZlRUe8FGOr14lALDyH987uhMGzNHHCxFCvelCt60EfbRGxwPQ2jsOWyIVayrVUml1HjtWOG9cr3lwamd3/vVrXZuY8Mdn1fHb9boWOjM7tgiAzp/vAeC1519A/cdhnrjJqc05Ljah6Pi2s8u1iR09RhEEwGvPv0BbdAIH+1/nyns+zVs++MfFB7jOwVo+Tnu6t9e0P20RdVgQ9Pf0cG7LRfn3aQozo1QsScqd8fbRTcSKkFYVFIFVO2GP7it0YrWb/Q3NzKbL/z2VyMQLJrDMmRHOWn3RIEcbgiKtHJPivJbT2PLkk+x7fgMAZ7edx7pP/ojxscIzu561vO1Dta0/lsMoggDY9t+PISL0tw0s4AbkNUCtSvomswlmfuj8mpyrPP5rgk0P/7bofdqTIWxPjLNzllM6QrCISJR0pRVBDRXByUOH868bprTV7LxeRnwPeJ7sldf/fm2EqRYTOVQ1thTqUu38+Rr6j3Xl309vnIPl2X/FP/jXrsUoggCIdzaglOKsd7+97P5aOF69Dqj2nl0sXLF81OccDL+dxTlbfI5c9A/AlCULWXzNZQCc03oBkxumkylZEfSkncZ3pVFEo6Gn43j+9fj5/paVSKeH6YPIFkbj8VOn1FiayiiU6V9dBZ3HjvHEjd9mYnwqO7teJZVNsjx2Mcv6Lig6zmvirG2Pi2KMIqgT/T09PPW9H3Fgxw6mxmfSmTrB6asuGPxDowhxPPDq1vzrXroHOXL0+D0B9FZh7c84CWReRXD2ZW9n4oxi22mmpKZQ+4KDrE88w/TVZ1Mrkp2F6zpnSe3OW45senhRSbnLsz7lf26KYfg8cdt3WNS6GIDOcSc5kThaNl+kXo1+TNRQnXj6c9/lrLblZLceZFJ8Gnu7t1c+OKeeR9H278S+/UzA6T2QmTbi0wTOb++4l7MOFAbZzuQJGhqbUJIllU0QteK0jBtolsmo4oHzshv/HIAX738QqE0eQbK7L/9au6qs7t/XtDCI3gNmSTAU3kF/7iUrOLxpO1M7Zg44LmJF2cBaVCpbowKR5TGKoA4kEwlmNRY3hGm4YnrF46UG8aO9HSeAebzW9QrX3PLpUZ9vaPx5+BOvnQQ3BP5g7z76Mr1MBexMlONvSXBy356yD0i6UpXRGlzbTY8+RiqZRLUnoAVe6XrB14cUIJsZXv5Drsd0pKEe9YW8GAdBNahUNp/0ePbb3sqiCy/k5L9sHHDc/t49XHvH532XxyiCOvCbz97OsubVnEweY3xsEscTRzj/uj/w9TvTp5zZak9b1xBH1gL/Hn4rWxi4j2YO5vMA0rEk5193TcXPlfoIakXHvn1M+E0EiDDVjWLKTPZz8BvZuXMrnkhTQy2FMYySNR//D7JksETyiiAWjxOLxzlZcmzfuxtYOP1tdZHL+AjqwATlOOusd09hfXoN3RcOPrvLTVpHNcfucgaQxlkThjiwNvhlDPAm1GStLO/86qfY2PQCl99auZzDlq4Xmfkn55XdJ/bobvlXH31ywDarMVrmyNqSGWb4aCTryBRv8q9RfTnMemBw5racxvyWM1kUc5L91icK3QHXW2t5ueUl1mfWsLlzHaevuqBuJkezIqgDE+KT2d+7hwvf/CcsfvObhv6A5ONHR0zMTUVf8KYhHNIas/PFF1nQemb+fTaqiMXjXPOlwU1dM969rGLcvD1KRdC58xBQbOaLtTaVP7gGjOQWWPeL+1nc5oQLN7a1DnF07alnuZEw8dDHv5LPhWmJOn6tt/3th/P7r/u//puAKmFWBD7z4D98ndboeE5ljg19sMtoqk2CU4a5QZpJZvp9Dxv1k63/WZw7QEN112Xe8nMr7rPs0c19pHOg7yHW6n8dn+FEDR3eWMjAbqi3IhhFgMMbmfYtm4sSInP4luQ5TIwi8JHHvv3dfFxwaurwi52N5JFKJhKMe9hmYctZ9GV6hv5ArfAheHxxgzOr7U6dAqBhSnWDWnUP18jkLVf0q2365BGdqzqcuyCTqT6PQKUL91rjuHGDHGmoF6/e9Wj+9dH+Q2RUhpPJowFKVIwxDflI36Zj0HI6L3c/yzv/4RNVf04sRz+PZIl9ZGch5v5ksj5NUvyIdT60ezdRK057z24i75jAjhef4/K/HH2/XcvKle8YmSKI00Qy08/OmTs4773/iw3//QCXXf7hoT84UkYiZrKgCFom1MdHZBhI96lO+k6dJNnXT1RiZLJp5t32dmbjTNjm+ZggNlyMIvCRNiaSyPTxjq99YnhZgaOYXR96bRfTXQdrp6reHDVaar0e2P74MyxkHsc4xDXvej+867qanDfvLB6h7mq0m+jL9PDOmz4GwGUf91EJeMgOZ0WQyIJ7uzW0tPgkUYXvruu36ceDf3UbbefPZtGbV7H39qeZ0+wUlZveMKeoAqyfWcIjwZiGaszTP7gvX5VyQmwyxxNHR/FPH/5j1XngSP61zNPrZhsOnRvbAVDDML93Xq04dmmF+k01YMuTT9IaHU9funfogwPEShce62AGnLHpLN706GMsa17Ngq1zyH7nYF4JgOMc9iukuRaYFUENeebHP2H+K7N4fs2PmPfBi2iLTuBA/95hn0esXNTQ8B+o/mOFsgcXf+iPBzmy1tT24V9gOWWTx51VfQ2fxW9969AHWTaQHZG4bQ8JRMdxLHF46INrjBpGQpmdDfKxHntrgmQiwcN/801aTp/CBE6veJzOisCsCGrI8ed2ATA+OpnXvv/44BVGB2OEpqGH/ul2skec79vQt6aOEQm1f/gtiXA80TGwRPdoz2s71RxHo7Z0bfLS39PDg3//NRrwL5zVMJBHPnc7KyIXE9s0+HPgrSSqG2ZFUENaUm3QAH3pHs5sWg5QscLoYORXBMPgN9/4V87tPo/cGBCZVb/BwI+IwbgV50j//pqf17ZtYPhtJb1NaFLUXxGozNAy//af72Z5djXUP3WgiLFmGGrKOM9aS6QQodWVOplvlpQjatW73Ef1+LoiEJErRWSbiOwQkZvL7B8nIveLyEYR2Swif+qnPH4zPuqEEU5umEbcbmBv9/ahK4wOxjAGWG9HKoCmKfWNFqllEtGDX/46MbuBlErW7JylDFd3PfF//y3/Om3Xrz+xUrnw0aFNQ1Zn8ENwvapl6oSNM8B783+mfmblgOMi4n8G+kjxTRGIiA3cDVwFLAZuEJHFJYfdCGxRSi0DLgG+JiL6qs0hGB9zaubnZgInZWRRO5IPcayeVooH/tnLz6lwpA/UcPzZ/NjjLOt1cy+k9orAcqOGhlN9dMvTz7AiWsgIV7aeg10sq0tdoeAVUj3JDfAxy3HMv9L5ApNmzmDPOcUr2og1BhUBsArYoZTapZRKAvcB7yo5RgGt4qjSFuA4oK9HZRByce9esiNMOM0pAjWMB6rRbuZ44ghbZ2xhzzn7Q5tRfPDlbfnXlqr97SnW8O20Bze+WvQ+iFlvporGNA2WJr6BEOiBx//tP7n/plv49S13jvpcUXeAb4k6pqGL//EDALz5fdezgTW8tuC1ip/VBT99BLOA1z3v24ELS465C/glcADHsvlepdSANbCIfAT4CMBc3eq+u+x7cSMzKXbOTjinfrI22k10pzt5xyf/om7fWaB2A2P/0c7862Rr7VcEdmT4iqD/iJPZ/HrPTuY0L6JxgZ5JWg1WfQvMhZlJW1o5Lb6Q1PHR32MRKR5GvUEa197yBY4dOEjfHTtKP6YVfq4Iys0LSkeMK4ANwExgOXCXiAzoMqKUulcptVIptXLKlPq13RsOh9c4M9mNvWs4tPoke5cd5M3vu36EZ8t3pqnq6F3rNzAuNjHfvave1HJ+rLqdme8GWct1t36hhmceOarbWaSenHGKzqtVIMpWZYdeEUStWNE9IH8aTEeiWjT98ZsG21k91cJuP5QTeNJMp3ve7u5tgx4XJH6uCNqBOZ73s3Fm/l7+FLhFOR6xHSKyGzgLeN5HuXxhRexiALItwspRZsHmfQRVPlA7vvM4i1vPp5d69B4oT62cxXbKhjhMOHd+Tc434Pw5H8EwQnQl6dSOb5k5pbpchRqipHo1G7Gi9Ka784PcrDPP8EusioTBWZxMJIjZjj9ltAUeobpooMl/dx5TI6tG/V1+4eeK4AXgdBFZ4DqAr8cxA3nZB1wGICLTgDOBXT7K5DvR8aNfnudqDVVLI04Zgcu+PvpaPCOiBs/+g1/6KiePdDBRnFnsvGVLRn/SMog9/BlgJON8ZubSM4c40j+q6VAWsaL0pP3tT/1G4Kl/+z622KSztYn+illDZ283NDdrV1bCi2+KQCmVBj4OPAy8CvxEKbVZRD4qIh91D/tH4GIR2QQ8CnxBKaVPSb4RMHVpLWdh1Y2wDXYTJxIdwd5oo5hY/fq2O1mWvJD1//BfzG5eAMDURafVSLDR0yBNpLMp5pxTx0gsl9xlrab6aFSiJLNOQmFgZgiF9s7iM9udrPWEe62SiZHnhdz/mVuI2Q2cTNavrpcf+JpQppR6CHioZNu3PK8PAJf7KUM9SCYSKKXY2b2ZS6762KjPV+hZXN0T1RhppDddx5LTZRn505861gsC46KOk+21rleYHfenB7DY1rAWML+9/dvMa5zLyeQx5gegaKuVNZlIELXipFWKxk+cxgXjyndo8x+9TUMPfvnrLKM4tyebTsMw/7cPfumrZLvSrIg7YcXHE0cYH5vEob52qi+Kog8ms7gGHNy+HVuEhKpRwbNhZhY7K4IgZySjfPjTQLQQfZGgb/QiVcCybbJQtchnHVwMEWjv2+2bTNUwVPXR3D2YJpV3TgaFrguCnS++mM9RATiVPE5zpJV0FaG5pSzqOYuWeCGTOHmGIvnWVhZMu6QWotYdowhqwJHXdjGDiWSs2qRADKfERH9PDzGrgaQKtv7NaB5+KwlEwXYVQVaG/2BWi23bVSeqvPjAr5jm+l96op1DHO0TVSqszd/+Nee2XFSze3Ck6LgeePoH99G1th1L2SxpczJ+X+1cD8BM5g2r+1uOxkghSWhz5zquuKVyD+0wYIrO1YDOgx0AZO3hdyEbLbvWb8ASi7QEqAiGEdlSDttttJ5XBFY9hpOhVdfBpzflX09/uz/O66oZJHx006OP5dsgZlt1GIr1WhPYzyVY2nphXgkAJKJ95NRWNY74UlLZQv6BnxOXemEUQQ1IHHPCNlWNMshlGGUQjrzqJKqkA54JVvvwH9q9m/s/e2vRtphbqyXX0Fv5qFCtiPNPqkraPmegeHXaK6MOCR4xVQi651dOtPWG1Bqu/ZfgGqDrysT4wNyj1nNn5FcvmfTwnx1v/kHWqv8EsNYMqQhE5FopeC8NZciccGbj9vja1HoZTmxz76HjAGTjwc0E1TASiLZ99RFWRC7moS9/I7+tQYprcUjcvxmlHclZQ4f+DjvtZCFPPH2+b/JUy2D9CBp6nftu6Qevrpc4oWHLk0/SHGnlSF9x3Z/V73sv+RXBME1Dh3bvLqob5OfEpV5U4yO4HrhdRH4G/IdS6tWhPjAW+NW/3IHdniVyTivNyTYysTQXvP/36y5H9KANbWC1BlnQqnol1BxxaiRnOpM88rW7AZgTn8vhvnamNTrxFtLg39+SKzpXDRHlrFQWrRpYSbJe5BK0stnK1zhuNZHI9LFoqT+RVsNjOBWy/Kf9hU0s5lwOZV5nKrMAmH2Le51cQVPJ4ZWZKC0no6I6/cUjY8inQin1PmAFsBP4DxFZKyIfEZGAq54Hy4zDM1jcej4Nm23aIhPoTJ5gSo3qIFnDSCib2eB854xVwdqwq80szuZKSWUUizvOZXHHubRGx3MiVUgfiTTrkXgTkzjJbILxU4MsazK0km20mjQIH3bQwUPhJXHISbBTU216093s6ho4jx1O9zeAjk07i95LXN+GM9VS1YijlOoEfoZTQXQG8PvASyISUCpr8DRGnDT+uB2n0W6iN1O7B9EaRoXMuN3I3u7tnHfVFTX7fj/J1RRsShTPI9KSyjvgoi3+lVPO+QiqISpxkhn/eiAPh2ymsh27MdIUWJ2p8ugxQ37oy9/gtKxT+X7SWfM446tX8da7PzLguGqa/niRY8WKw27St7x0tVTjI7hORH4O/A6IAquUUlcBy4DP+iyflnSf6qTRduzaUStOY6S5pg9iteGjh3bvpsFuojcb/GywWr9G1p0zntl2bvF2ybC5fx0A81Ytr6lsXiLDqD7aFGmmP+NfTkOtiNuNJLK6yKnPmuDc3pX53iCLL7tkwP7hNP3x0phtIZ1N0ZVyqtJGm3XpAzFyqvER/BHwDaXUk96NSqleEfkzf8TSm62PP8F0GQ9Ac6SFmBX3NQmqEtsff4aFzCNpBztrrUWhsayV5do76ldtdChT1skjHYyPTWJPz/Y6STQ4gw1WUYmRUvXrmhYGHrj5NpazGoCNPWu5ZlJl/0k1vR68xK1G+jO9ZN1m9NkRRB3pRjWmob/HUw1URBpFZD6AUupRn+TSmiMvOyGb3alTxG2nyFwyWrvBWKp0aHbtOwJAtkGfWdhQVCr7q6L1+RusSHU5lGu/8yMiVpTu6CmfJRodJ490ELGipLVSBMGbhmb2Ffx10y8f3H9WTYlvLzHb8R3tGb+Lo/2HWPFHAYUW15Bqnor/Ai72vM+420bRjDfcZI4nIA6nUifyXYkmXrSoZuevtvpots+ZiViNejirkonEoIXvfn3LnZzTtLzsPonWJ0K56sJ8+1PQChMuXOCvQFVSyaF5YOurtCFkNGnspwKck+zftp0tt/+a1PQMZ8eXsqtrK2+9+8MVa//kSnxXk1DWfaqTRE8PqUQ/k+PTOJo4xDVf+nQNpQ+WahRBxG01CYBSKhnmvsK1IJqMQRyOqoNMy87iVOo4K3//92r+PUMmlCUVxMBu0iPKZijOObm84j5p0qvaSROtJLMJLnh3aXfVgBjYuA+AY3v208ZsMrYeiiBI1t/9c5a3XUxfZzfRSJxuOTno8cOp7Lrl737JlIYZ7O/dzfyWM2vWf0MXqnn6OkTk95RSvwQQkXcBoS4VPVrmN5xBRmV451c/6U/p5yrz96w0EIP4hBE2R64x1VZx3Nm1hR7pzJdFAH8jhcox1INsS4R0NhV4DfnBGtM8+Fe30ZBpgrbZqIguSU3BLQlaM+MBaIw49aGyLYNfk5ykQxX0SyYSzGyaB8DspoVAIR/mjUI1iuCjwA9F5C4cJfo68H5fpdKYjY/8hknRcfSlu30bJKr1EUjWOa5lyqQhjvSXap3FmWwa24qQOSfClGlnkH42lc/QbJgwoEOpb6gq7Be22GSUPrNslS0e1J758U9Y1ry6sD+uT/J/UHPlCbHJRe8bZ08c/AMFTVDxkBfvfxCJRJiK29rSvV/b+3Zz1ogl1Y8hFYFSaidwkYi0AKKUCq4fYkA89PGv0KRaaXjbFE7s2s8kVrA1s5HTucqX77OrVASWcnwD42fP9EWO4TJUOd+USrKvayeXfuzPnQ3vhvabnwKgeXL9GsKrKrqn2BIho/QtJpbqLo5SE43CNoNQBQd27GB8rHhCtOBNQ7gxXTEr+V8e+MytLI9ezKau55jaemF++4bUGi7/xqdGI652VGWYFZFrgCVAQy5eXCn1ZR/l0obOY8fyJoytj28g09jnlEyeNPqWlKPFVs6/b9qihQFL4jBYzZZkIkHMaiBFcXTV+sQzLJAzWXThm/0Wb1hYuq0IBgxWxe8XXr0aHQhKHb3yi4dZLOeys2sLi1oXczxxhHNXDF5yY6jyHVNTsyAKrW6oeI6lH7w6cJNhrRlSEYjIt4Am4O3Ad4A/JITN5UfKpkceZR5Oo4+z2pbT0X8QojBtmX+tFC27usJotkTIZNO0TQrWNFQNj/zjnSyXC0lSXNflum/cHIg8UsH2vuXpZ+j48Sssal3Mkb4DdZaqerLpgiJo79nNRW/VyFrr04IgmUjwxE3fJi4NLLzxTcxevITNjz3O0Z9uI4KCVuie1sPsL72lyi5huaihgQr/5JGOvF8gWtKTeN7SpaP8S/SjGhvExUqp9wMnlFL/AKwG5vgrlj6c3NYOQE/asYhNiE2mo/8gSy69xLfvtNzM4iEdmkS0ih8fLAxv4knHfpuZWi9pBkNBhYisXT97ikWtTlmCqKVP6QBVMmtN9xX6T2S1MmH5tyZ48lvf4+y2FSxsPZtX7/otAPt+uo5FrYs5o3UZ4JSSGC7lkvU2/OKB/Osmu2WEEoeHahRBbi3fKyIzgRSgR3B1HZh4zHE4HU84yVv7enay4pvvoaE52EidX934VSbGppDWwnwx+MP/9A/uY27LIg707uWavw8+9nowaSVdeCRsS5+Q1myJQzOTKPzfs+gSMeTgl4eg/1Ahue/stvN46MvfoE2KV8PnXPHOYZ+3rI9gQ0HRNkffWBFC5ahGEdwvIuOBrwAvAXuAH/sok1ZMijtT2PT5MY72H0Iu8F8B5KOGKoxYW9c+y9LWC5kQn0wqG2yLSi+VGnx0rXVqwXconUwt5YcrO1MY/G3RI1GvHNmkRxFUyDEIDn9UgXQXPxCTOibRFh1HRmXoSp3i9Z5dtIwbQfRZyfVLJhKc1lrIRo5ZcTIqw3prLRsiz41Idt0ZdMrjNqR5VCl1EviZiDwANCil9M67rxHdpzppsJvZ1vkyl33wxvp9sWUD2YrP02v/8wQrxEn27ksHX2wsH4VXwVlsu9FN53/6j+ok0VBUXhPYeBWBTiuC4sFKeRSB0mpFUFvT0LEDB9n4T/9Nhgxz46cDEPmL2ez++hPMaXay+Xd3beMtd//58CV1/USlobkde/YOOPZU8hjXfeON2/1t0BWBcmoGf83zPjFWlADAq48+hiUWCau+JX4te/CZaKS7sF+PQWDwh98mSlZlmThTjzDXwaJHvbWQdFIEA8gUrnkGnXwEtWXt177PGW3ncnbbCpoiLbT37Gb6ggUcjR/OH9OvRvd8lpqGju4tKIK+tNPP4GTq+Ki+Q3eqMQ09IiJ/IMPpn/gGoeOVXQBkGoIZbCtdcO+sNWbpE8ZWLlV/54svcmbbuSiUNiF3gyXARYjmzW06KYLSJDiva0hpZBqqtas43lfIOH81sZ6L7nSio6776hfyARyjrb7rdcQ/8JlbOfw/m/PvO1MnATgVPzaq79CdahTBp3GKzCVEpFNEukSk02e5tEB1OKaOpgX1Dc+03RVBpYcqopxZ6/6ePRycdrBOUg3CIFOEvf/u2FR1s7dXEjliRenP9PF6zy5eluDtwRVLTHhWBPo5i2s3ZxwfcaLNjvUfZsblxT0sdiRe4XjiCM3nThvVd3gd8cujF7O47XwAOvoPknpTjO2dm7j4Mx8Y1XfoTjWZxW98l3kZHvib21jevJpkpp83ffCGun53rq9upaJztkRJZPq48M4/qadYQ1KuZotuCqBA+WsbkSipbJLVd+r14JeaLyRbkF+JRoqghkuCZCLBxPgU9nRv5813fWjA/mvurI3NvtT/kqM9spvr3vMFeE9NvkZrqkkoe2u57aWNat5ojD81CVpgV89WFjYPPyRtNMgQrSqdwUqf/IEcw+39GigVBqyYFSOt47UtySPwjv26rQhqxZrv38dp9kI68cc+n3cWu2a3zmMl5p/Y2LGGV2ME/ZzndQOwCngRuNQXiQLmgU/chiiYYs3kZPIY77hHv7bMUStKWiWHPtBQlsF8BDE7xqmkTv1/yyOqYNXVI2Agx/CWBMlEgqdv+g7905Nc/aWbiva1vBKDRogs9DdkOzeB2fLo48ymkPFoN+iTUOg31ZiGitrviMgc4DbfJAqY5U1OzZaj/YdIZoKJ0beH6KsbsaKkszokkhVTrgm4Tg5XL5VCH2JWA0mNcjPylK4IlNc0pE/BueFKsu7nv+SMtnNJdRdPbPZv2860hlkkMn1c/KH31U7AMuRWWyd3HShSBNHW8PcirpaR1K5tB86ptSC60RodF1iy1lDVR3UzDQ1W1lmnqKZiBmqC/p4eolaclNJJEZS/tuJ5dLOWTiuC4aWTRdY41zpqxXjpk/fxwCduBWD9D36BiLBFrR9ZklhVuKYh17eV6izOyWmYMM6n79WPanwEd1K4Gy1gObCxmpOLyJXA7YANfEcpdUvJ/s8B/9sjy9nAFKVUIEG7B3bsyL+O240kAza/VIrYjVrRfOicTpSr2RJxVwTrE88wm8GrQdaP8oPrrhdfpE0sUqKf2a00RNTyzuEsfVYEwyWXuQ8wtXEWsaQzcYgdj0IrzL38PB+/3a2knHMW92XBM29pqmNp9KCpZkWwDscn8CKwFviCUmrItZqI2MDdwFXAYuAGEVnsPUYp9RWl1HKl1HLgi8ATQSkBgO2PPVX0PpUNZkAQe3DbZFRTh2amTD8CWyIc7tsfWJXR4XBk204A0rZO17b8ZCDXiwIq1s8LkOoEOrBjB3G70ano6zI+Npl1n/wxi1vPpyt1kmWX+xeoUcgsdn7bqWKT7OR51dUwfSNQjQH3p0C/Uk6JQxGxRaRJqSHT+VYBO5RSu9zP3Qe8C9hS4fgbCLiGUdeWwxA/jUN97QjQN310iSojRWxrUFtrRKKk0WmwqowlNplsMNexEk5i8cDBqvfQSWe/hh25S8sgNFmFipj2RJ3Mb6pq29D2x57hNBZyML2X7u5O+lQ3i1vPZ3qjMwAf7N/L2T5KWhDUubZ2tng4nLZQjz4f9aCaFcGjgLcLSyPw2yo+NwunrWWOdnfbAESkCbgS+FmF/R8RkXUisq6jo6OKrx4ZLck2MirNvM+8ifNvv4FrvhRMpczBSkwcO3DQcRZrVH46hyrT8i9i2fp1+qrg08j2OCtAq1kfB3fprDXHhHihLeOFH7q+rjINxnCMVPYG5x7OtCnectefk5pWrOyW/c0f1FCygeS6uuWubYTiGUDQFYbrSTWKoEEp1Z17475uquJz5eYFle6T64BnKpmFlFL3KqVWKqVWTpkypYqvHhnNdhvdqVNMmTvXt+8YFmWu1qFt2wDIiD5RQ4NFrVgS0axe/iC4C5f4RJ3qz5efXjfazZxMHuOVrheYNHNGnWUanGozi8fFnBLvS/7ocqC4l0A9/q7cXZtTBLqaXOtBNYqgR0TyHhsROR+opuRlO8UNbGYDleoQX0/AZqHHb/wWM5vm0ZcJPobczq8IBj5Qx/c6lzBj6aMIcpRrTBORiFYtHwfDcnsRtM0aXckCfyhc2/6eHiJWlEP9r3Pl3cH3dyim+jVBY6SJ3d3bWLhiOQCLL7skv68uf1euZ7GrCMZFJnAy+cauKVSJahTBp4D/EpGnROQp4P8BH6/icy8Ap4vIAhGJ4Qz2vyw9SETGAW8DflG11DWm89ixfP1xHRSBFansLO7tOAFANqJPyGBOXZUrOqdjE3jnsR+oZHM1nGYuPr2u8gxGuab0x9qd/g5Z0eu6DodjBw7SaDfTny08b22TJrG5cx0bG16orzBKcfJIB+PjkziR8s/0rDPVJJS9ICJnAWfiPD1blRraQK2USovIx4GHccJHv6uU2iwiH3X3f8s99PeBR5RSPSP9I0aLN6PQe2MGTbkFdqrLXYzFR5IC4g+V5oDJRAJbImS1K5NcLPFj3/4uLZsbaKCJrMowfZF//ahHitdHcLx9PxOIkCEcK61ybHnkMRYwZ0Dl0CvuuanCJ3zA43/Z9c+/Y2rjTHot/cKy60E1eQQ3Aj9USr3ivp8gIjcope4Z6rNKqYeAh0q2favk/feA7w1D5ppzbOvegiKIBa8I7Ejl5vWqJw1RiLTpFCniUFp07viBA4iI9gNWZFOWGS2OFbM/06tNuWwor2Q7j3QwgRnaJZJBRT/8AE7tOgDMIRuoPzZnG1JMbXR6ZajxFiEJyKsp1UwrP+x2KANAKXUC+LBvEgVA9nghX2DKxcGbBaxBMoutpLOvZaZ/TvNhU+HhP77f8WdkdaqO6eJVsX3ZfCxEYLkjQ+FdEfQfc3pDqZAmkj1w820sT14IQNPs4JK2cjWnsp4WqxOXzA9ImmCpRhFY3qY0bqKYhpHWI6c55USJvNq5nove42/IWjUM5iOIZFw79tIz6yVO9ZSEj/YcOeps1syWrUpalHmjXLRTBCUOTYCkax5U+kS5ehhaOTV2FpYBC950gZ/CDEruv546VYh9Oe+6q4MRJmCqUQQPAz8RkctE5FKc6J5f+StW/Vhz339xRusyjic6eOc9nwhanEHZv207S9pWAjDnHI3KPeUGK0/U0P2fu5WJa50oYx1NGF5sCopXpxpOlcj0OcpKNC2TPFj46MNfuZsz2woNZnIRQ4HgipntcSYqG3vW0tDczKau51ifXhOcXAFQzZziC8BHgI/hXLr1gF6By6Pg5NN7mNsynfbUTs4d+vC6EHGrj5Y+UC///NcsZQWAZnbsgbPAJZxHzHaqN2o5c/VcWm+FVO1WBDk8xneVyICANOh4YQdncvvEfHrqxp61gdafyl1RSQHRQiTeVXd/NjCZgmLIFYHbwP5ZYBewErgMeNVnuerGOCbSn+nlHV/TZzVgRco/4Cqpl4mllKzHfCHiubUa9Ju5ess4RzyKQLuch3LJekk3E7ZJn8lAtXiVbq06jI2WnLlVGvSJxKs3FacUInIGTuz/DcAxnPwBlFJvr49o9WFCbDInEkc5TaMZdqXZfrbPMVu81rVJo0qeUM4u7K2OGWnR59rCwBVMRAqmoQa7sfRwLfD6CCTjXNv4eJ0yoB0q5WjksHRqXeq6Pm13yWq3jZ3+A6UMtrbcCjwFXKeU2gEgInUM8vWf155/gbbYRPb37wlalKpQCQUx6J+j2azVJZspyOVdETRM0qztdYneilgREpl+4raOA0HxoPqbv7yd5W1O86TmSeMDkGcoyjuLD+zYwYl7XmFiXKNoN8nVGHImAg1alRapL4Othf4AOAQ8JiL/JiKXMbyeE9qz8/FnAeiPV1Mxo/6U+ggk7bxv1G1gdfH2I7A8iqBtpoYlGzyXNiJRTiaP8XL3syRWa2p3d30EZ7cV6vO3ztDwulK++9uWBx9lXGxS/YUZhNzzZVvO/7x50sQgxQmUine9UurnwM9FpBn4X8BNwDQR+Vfg50qpR+ojoj/c/9e3sSLrzKz0KuPrUK7rl+2aBFqmTh6wTyd+fcudnMPy/PvpZwSfm1GMKlKxthWhP93H1Xd9ruIngkLlK2QOjLyavmhRvcUZMX0HTmo3jcw9YbY7DLZM12i1UmeqcRb3KKV+qJS6Fqdw3AZA/y4jQxA/VUiFmLIkHHXHc81IpiycH6wgFciFj7a0F9vZp8yfV+7wwCi1Y0dEzx7QMHDsTGQKq9fxUzUduMpYh+weZ6jZ0bWZDf3PsG321joLVQb34kbcFcGUuXMGOfiNzbDWwW6Z6G+7P6Em6ulJd/Zl+vm/S5OeoGDL1L1hRqqkxadOoa7liFgRMhr2d/CSWyFqF9VUjjK2oVjW8b8s/Zt3aVc2OyIRsirLuGl6mtrqwZiNl4qJsyJYn3jGx+bYo0NKQgdtiZDKJvVtmOH21Y2JnpE3lYhKjLSu9ZBKxlTdKrmWUi6nBJxVVyqb0EsJuNfWdkul6z5h8ZMxqwiiVpyTyaMa99Id+EBFJKJl44xCFy1HETRGmuhOdQYp0hAUfAQnj3RgWyHomRCiFUE5V4AtEW3Nb3aIemb4xZhVBHGrgaSuWaQ5SrqS26Jni8pSGu0metL6KgKvij2wfTuAthVSS6cDWaV3uY5KpYZsiZDWbbB1R7+Ipa+SqhdjUhE88vV7mNQwTcvZdY5yiTm6rghyqEyWZCJBo91Md9qp634yeTRgqSrhXNuT7W6FVEtzk4s7/lfbBlI3nE51et27OVdGmLro+cWYVATJfc5s9YjsD1iSwShjGrKi+s2qStjx3HNErCh9dLM+vYbMlTom6RSube8R/Tq+lUO5mkDKBelrR5nubxqahlQ+jyA65hWBptkz/pJL0Z9w0YKAJRkeEYnQn9Ez+Q2cMgjtL2xiMeeSjia57qu6+l8gN1gljju9CFTlyt/BUjLwi+Zzt0rOYsc0pNmKwP0dkaj2Tni/0fuu8gk76+i/SfPnBizJIAyMHtV+RZDNZkgedTuOtmpUU6YEb66e1eHMtCcs0yvXYQDugsUSoSt1gu3ztgcrzyCUW7M4IbqaDbauoJZYZHWTrc6MSUWQa1I+e/HigCWpjCrJfgU97awD6HNG2XhI6ra0yUT6Mj2s+qPfD1qU8pSEEAsWJxLHuPRjHwpIoJGhY9SQNxZDeye8z4xNReDG4+uaP1CJiBXTfEWQxUq7ZreFswOWZjAKSjZuN9KX7tE+hjxnchGRiuYXnYloaIf3TrSMIhiDOCUFNA8dBby3an9Pj2vL1OthKiWadRL1FlywMmBJhsK5tjErRjKTCFiWygwoPIiFQvNBq4xDOyJRMrp1hfeuCHS/pj4z5pzFyUSClsg47RxXZfFM/Hat30CbCGnRV4EppYhKnFQ2yWydMkhL8M6nY1ac7lRXYLJUjSu0JRZZjVcEpauVYwcOkk2niFhRUro9c54KuWZFMMZ48qZ7mdwwnYTGs0AY+EAdeXUHAGlLvxVBPrM4kyUqcZLZ/oAlqgJ3NhizG0gpfe+F/F2gcpklUrYyrVa44q37xf303bGDDbf8D4B+kxiP/0VhnMVjiibLqeV/dMHxgCUZGu8Ku/egI282rvcg0Gg30p/WN8TVwfERnDzSQcyKk9RYEXjNFx379mGJrb9pyOXIRmfycnab02c7E9VssPU8YGZFMMaIWBFOJI7yjk/+RdCiVEHhRs10ObMpq03XgHcnj6Ah0kRfpjdoUapi5/PrAA1nqmVQWUjcs5eoFdPeWZxLesv0lFzXRr2S4YqcxSFRrn4x5hRB1IqFwz9Q8rBLwrltm6aND0CWKskqmuwW+rNhUATCyT3tAGQims1Uy5BNFAZV7U1DLlKyMIyM06wqrXdFYBTB2CIXOqo7pY96NO32IlhyZv2FqZKeI8eIWFESSn/TEED/kVPOW83Gp3Ko3sJAFRbTkJ1xYlEO9O4FoG3+9CDFGYhHEShjGhpbRKyYdoktlfCGDrbZE+lJd7H4zW8KUKJKOANr6rijANK23isuJ2lbyPY494Gt20zVi3sLSMozaGlsGvKuVqLKCSWe/YmLeLnlJS6+/o+CEqs8Jnw0z5gLH41a4SjlTMnyf3xsIicTelfylD4Fjfo7tPOhmEkLotAyS9OWjx5y/apB8xWBZ3CNSoxkNsHC005j5t9+MjiZKuGRVYnG17QOjLkVQVTC4iMoJmrFSOgc3QLYaae+kM4ObS+RjCPnrKVnByzJ0NieqnhK9Fa0uZWsrXnZdO+Ke6yvCMaUIti1fgO2FQlHlEjJe52zinMDU1Q5ZRqaZ0wIUpwqcOUlRlZlmb1Yf0WQ61cNmjuLPbJZYutXaM6Ld0VgFIF/iMiVIrJNRHaISNmaxCJyiYhsEJHNIvKEn/Js/q9HAEg06T2zLuDcqf09PVrWaikl6vaBnnKa3uW9c4Vdxa06qXudIXBq9eTQ2UfgxWkKr/E968ks1n2V5Te++QhExAbuBt4JtAMviMgvlVJbPMeMB+4BrlRK7RORqX7JAxA9FYFWWHj1hX5+TY0o3JiHd+3CRt92ioW6PQ1kVZZ5550XsDzVIYj+JoFcO0XviiAk9mzdVwQePTDmFYGfK4JVwA6l1C6lVBK4D3hXyTF/DPy3UmofgFLqiI/y5MtPL1p1gZ9fU3OO7tkHQFb0fajA6VXcn+kNSVVXcQq46Wxm8WCHZPbqlczWXBEUhY9qfE3rgZ+KYBbwuud9u7vNyxnABBF5XEReFJH3lzuRiHxERNaJyLqOjo4RC2Rhk1FpGpqbR3yOepK7TbuPHAP07asr7uPfGGmiL9MTsDTVoEByJZ31nl3nxipL9G30U0rBWWzrbc70phZbRhH4Rbl88gE+UOB84BrgCuDvROSMAR9S6l6l1Eql1MopU0Ye6meJpfcMxYPytChLnHSqY6qInjdrTqpGu4W+tP5ZxTl5nQJueisC5RlUc2QtnWUu3KO2RMhk9X3evFFDKjx61hf8zCNoB+Z43s8GDpQ55qhSqgfoEZEngWWAL334LLHD1ZLOvU9T3Y5zW0X0qtVSiiUWiazuWcUOjmFItC7p7MW7IlAhyf7RfUUgdmEeLM0huag+4eeK4AXgdBFZICIx4HrglyXH/AJ4i4hERKQJuBB41S+BbPS+MSuh+hyZpVHTaUtRhmYYFG1u8NffR5C7tJbXs6l7moYrtC0RMhrfD95LOu60Uqv12MI3NaiUSovIx4GHARv4rlJqs4h81N3/LaXUqyLya+BlnPbc31FKveKXTGFbEUiuqaqbsRsb3xSsQFWg+8DqxQqBjyCH1zQkcU0nBAx0Fmv9vHmcxYvfcUlwcmiAr+shpdRDwEMl275V8v4rwFf8lCOH9lEMHryx4i3pcaSzKVa9T7NaLWXQPhyTQs5TKKKGBFDFpiG7Qe8lQd5ZbEW1ft7EowgmadxRrx6MqcxiCys8DSg849OE6GROJI8yfqqmNXGKOj1pPrB6EMKzIvAqgmiLxkXyXMXasW+fM/HSNvcFxBpTw9+gjKkroXuCywDEeaDGxydxMqVrwbliwpHspBDEDR/VW3GpvL29oAjibS0BSVM9W3/3NABJW+O2paJ38EU9GVOKQHubZRFO4OCGnz2ILRF6Ijo3WPfWddd7YPUiCFnN5c1dWa8iaJqscS0nV+BTO/cDkNU4ZUcsowhyjClFEKYVQa5VearLmVG5pd21JwwZmvk8ArFCaRoaP8PXSiyjIq9XTznXtWm2zkrLKIIcY0oROCuCcDz4ObJJR3FJVN+b1mteCcvAiptHoP0KxhOKmWPSnLkBCVMtki/xPWP54oBlqYxZERQYU4ogTCuCHCrlKoK4vgkv3scpDCsCUIjkVgRhkLcYbYMGgNx6y3JTdafMnTPYwYFiFEGBMaUIwugjIO08WHZc75DBHOFQBA5hKDFRlPUUEgQnQg9g3LRpwQozCEYRFAjfXTYKbLFDkvnqsWO74kZbGgKTZUi8z1NYFIHKhY+GRF6gvWc3k/8uHCW+cwUe9e71MKaGv0EZU1fCElvrlPeBCJJxa/23aBx+4UGFpYqjhCN81KtYsyoTmsq5ltv0R2fMiqDAmFEEyUSCiBXV/uYs4MYNKedf1DihNUhhBsU7lKoQPFvKNbtJGBIMPZEtYei1naua66wI9H7WTEJZgTFzJY4fcAqfhsU05CBYWcfp1jRpYsCyVEkYZlm5EhNhWBF4CIMiyOGsCPRWshJC/4tfjJkrcfLQYSAsma+FeOxc1cnx0/V1uhURojsqDOGjXrWalnAoAhHHR6D96jsMk5Y6EaLHdnT0HHW7fIUmzt0hF4Y3cYbGRbE85guxw/JwSejCR3Wu21OK8RGEizGjCHpPdAK6d3fyotwwvHC11ySi/y1V8BGEIXy0MFhlbM1l9eB0A9Rb3lxjGt1NWPVA/6e2RiS7nF66oYlqAUDC0V7TE9kSnhVB+HwERMMiq4QiVDtXhjo82fD+MWYUQarHaaEYlt6k+R5aIUiC8/Z+lRCsCHIIIag15K2H06C/ks0pVisE5VwsN2pIdz9RPQjPUztKMv2uoy0kigAAgQarkWQmEbQkVWNF9S2FUYQ4qy3txwDP2D952aLg5BgGucxi3ScwluUMBmHzG/rBmFEEKuH2/Y3pP6tycOzYE+NTOJE8FrQwg+IdS62Y/po2N2sVJFSDwEXv+YOgRRgaT7Sb7iuCnLNYez9RHRg7iiDpPvwaF28rpcluocFu4hThaEoDYMfDUi87Z9LSfEkQlnlLERIOk6brLA6Vn8gnxowiyPmtdO/36mVSg5M7YM3VuM4QFA1WkYZwKAIRJ3xU91lr+Cj4CDKar7aybmVfsyIYS4pAKVLZBNFmjfu9FlGYpVz0wesDlGN4zF+1ImgRqsYSW/vZYM4RHxaFlbuaYaj0m0olAchqfg/Ug/DYSUbJdd+4GYAFActRLblbM6symtefL9CdOsVZS98StBhDopTCEkv75upedFdYXgSISISM0vvaZvodRWCihsbSiiBsuPem9jkEkDcNaR+K6SHXA1j3WPf8tQ3JisBBiFhR7RVBNu3877Oay1kPjCLQHN2X1150bwSfR8C2nMVwVjS/vhI+h6Yllusj0HuAvfj917O982U6lpwKWpTAGTOmofDhPPjhUgQhmbUqRcTtARyWkiNhWhFELCcgQ/feH7F4nEvvuTFoMbTArAg0JTf/071ei5dwmYYcRaB7yZFcpeSwrAgUiog4iiBr6a0IDAWMItAc7W3YHkKzIsCjCCLhGWDDQm5FkA1RkbyxjlEEmhMK01DoZq2FwYqo5o+AhCt81IsyhufQoPlTMJbJ+QjCMwCER9aCwrJi4XgEwqJki4iHMi16TBKOp2AMUsgjCMHg6i5awuQjyGE1aZ4JnQ8fDYsi8MiZCovMBl8VgYhcKSLbRGSHiNxcZv8lInJKRDa4P1/yU54wEgrTkDv+h0JplRBr0TvTPJdZHEYlu/j6dwQtgqFKfLPiiYgN3A28E2gHXhCRXyqltpQc+pRS6lq/5AgvzmwqFFFDWUfWsIQ4euep8fGtgckxHMJiGspJubNrC287/y8ClcVQPX6uCFYBO5RSu5RSSeA+4F0+ft8bkjBEDUnWdWiGZLDyNiGYMGt6gIJUQc4RHxrTkENapYIWwTAM/FQEs4DXPe/b3W2lrBaRjSLyKxFZUu5EIvIREVknIus6Ojr8kFVbwmBuyXWqDIOsXpRSzDvvvKDFqIqwmIZyiXppjCIIE34qgnIhA6XTmpeAeUqpZcCdwP+UO5FS6l6l1Eql1MopU8JRgG20qPzgGoIVgcqVQQjHYJW7M5PZflrGtQUryxCoTM7sFo4VQU4RZCy9y0sYivFTEbQDczzvZwMHvAcopTqVUt3u64eAqIhM9lGmEBGe8FFRuU5P4RisQiImACpXMz8kZjeTTBZO/FQELwCni8gCEYkB1wO/9B4gItNFnIwZEVnlyqN3X8Y6EbGcsMZ+1RuwJEMj7m0UlraPJ9OOeTFu6x0xBKCy4VoRRN37VmkelWsoxjdFoJRKAx8HHgZeBX6ilNosIh8VkY+6h/0h8IqIbATuAK5XYbnjfaY1Og6A/rb+gCUZmvyKICSKYPW//GnQIlSNyjrXNCwrgpgVB8BuM5ogTPiaBO6aex4q2fYtz+u7gLv8lCHsnPXutwctwpBIrgxCSBRBy7g2nu58gVQ8yWw0b6STDpciyK2ymmdOClgSw3Aw1UA05/RVFwQtwtC4Y1RY8ggArrzn00GLUB3uJQ3TtQWYtviMoEUwDANTYkJTNvasZUP/mqDFqIozP3YZu7q2suDDbw5alDcc+aihkKwIciw8Lzy9qw1mRaAt19z5+aBFqJp5S5cy7+6lQYvxxiQfRhwuRRCLx4MWwTAMjCIwGHRG5VYE4TANbbDXYp0S/X0vhiKMIjAYtMZxxGdCkFgIcO0/h2clayhgfAQGg8a8/UsfY3vnJtrePS9oUQxvYMyKwGDQmJZxbVx6z18GLYbhDY5ZERgMBsMYxygCg8FgGOMYRWAwGAxjHKMIDAaDYYxjFIHBYDCMcYwiMBgMhjGOUQQGg8EwxjGKwGAwGMY4ErY+MCLSAewd4ccnA0drKI7fGHn9I0yyQrjkDZOsEC55RyPrPKVU2abvoVMEo0FE1imlVgYtR7UYef0jTLJCuOQNk6wQLnn9ktWYhgwGg2GMYxSBwWAwjHHGmiK4N2gBhomR1z/CJCuES94wyQrhktcXWceUj8BgMBgMAxlrKwKDwWAwlGAUgcFgMIxxxowiEJErRWSbiOwQkZuDlgdARL4rIkdE5BXPtoki8hsRec39PcGz74uu/NtE5Io6yzpHRB4TkVdFZLOIfFJXeUWkQUSeF5GNrqz/oKusnu+3RWS9iDwQAln3iMgmEdkgIutCIO94EfmpiGx179/VOsorIme61zT30ykin6qLrEqpN/wPYAM7gYVADNgILNZArrcC5wGveLbdBtzsvr4ZuNV9vdiVOw4scP8eu46yzgDOc1+3AttdmbSTF6fRb4v7Ogo8B1yko6wemT8N/Ah4QOf7wJVhDzC5ZJvO8v4n8Ofu6xgwXmd5XTls4BAwrx6y1vWPC+oHWA087Hn/ReCLQcvlyjKfYkWwDZjhvp4BbCsnM/AwsDpAuX8BvFN3eYEm4CXgQl1lBWYDjwKXehSBlrK631lOEWgpL9AG7MYNjNFdXs/3Xg48Uy9Zx4ppaBbwuud9u7tNR6YppQ4CuL+nutu1+RtEZD6wAmemraW8rqllA3AE+I1SSltZgW8Cnweynm26ygqggEdE5EUR+Yi7TVd5FwIdwH+4prfviEizxvLmuB74sfvad1nHiiKQMtvCFjerxd8gIi3Az4BPKaU6Bzu0zLa6yauUyiilluPMtleJyDmDHB6YrCJyLXBEKfVitR8ps63e98GblFLnAVcBN4rIWwc5Nmh5Izjm139VSq0AenDMK5UIWl5EJAb8HvBfQx1aZtuIZB0riqAdmON5Pxs4EJAsQ3FYRGYAuL+PuNsD/xtEJIqjBH6olPpvd7O28gIopU4CjwNXoqesbwJ+T0T2APcBl4rIDzSVFQCl1AH39xHg58Aq9JW3HWh3V4QAP8VRDLrKC46CfUkpddh977usY0URvACcLiILXG17PfDLgGWqxC+BD7ivP4Bji89tv15E4iKyADgdeL5eQomIAP8OvKqU+rrO8orIFBEZ775uBN4BbNVRVqXUF5VSs5VS83Huy98ppd6no6wAItIsIq251zi27Fd0lVcpdQh4XUTOdDddBmzRVV6XGyiYhXIy+StrvZ0gQf0AV+NEuuwE/iZoeVyZfgwcBFI42v1DwCQcx+Fr7u+JnuP/xpV/G3BVnWV9M86y82Vgg/tztY7yAucC611ZXwG+5G7XTtYSuS+h4CzWUlYcm/tG92dz7lnSVV73+5cD69z74X+ACbrKixPccAwY59nmu6ymxITBYDCMccaKachgMBgMFTCKwGAwGMY4RhEYDAbDGMcoAoPBYBjjGEVgMBgMYxyjCAyGEkQkU1IFsmbVakVkvniqzRoMOhAJWgCDQUP6lFOewmAYE5gVgcFQJW4d/lvF6XXwvIic5m6fJyKPisjL7u+57vZpIvJzcfoibBSRi91T2SLyb+L0SnjEzX42GALDKAKDYSCNJaah93r2dSqlVgF34VQNxX39faXUucAPgTvc7XcATyilluHUt9nsbj8duFsptQQ4CfyBr3+NwTAEJrPYYChBRLqVUi1ltu8BLlVK7XIL8B1SSk0SkaM49eJT7vaDSqnJItIBzFZKJTznmI9TFvt09/0XgKhS6p/q8KcZDGUxKwKDYXioCq8rHVOOhOd1BuOrMwSMUQQGw/B4r+f3Wvf1GpzKoQD/G3jaff0o8DHIN8ppq5eQBsNwMDMRg2EgjW53sxy/VkrlQkjjIvIcziTqBnfbJ4DvisjncLph/am7/ZPAvSLyIZyZ/8dwqs0aDFphfAQGQ5W4PoKVSqmjQctiMNQSYxoyGAyGMY5ZERgMBsMYx6wIDAaDYYxjFIHBYDCMcYwiMBgMhjGOUQQGg8EwxjGKwGAwGMY4/z9bcUpyMUpgxAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# Plot accuracy\n",
    "for history in histories:\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "for history in histories: # Plot loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('GP038.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
